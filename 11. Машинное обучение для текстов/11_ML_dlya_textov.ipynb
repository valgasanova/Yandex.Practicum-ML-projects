{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tbl_wao8G0f",
        "toc": true
      },
      "source": [
        "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изучение-данных\" data-toc-modified-id=\"Изучение-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Изучение данных</a></span></li><li><span><a href=\"#Подготовка-к-машинному-обучению\" data-toc-modified-id=\"Подготовка-к-машинному-обучению-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка к машинному обучению</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Проверка-на-тестовой-выборке-и-сравнение-с-константной-моделью\" data-toc-modified-id=\"Проверка-на-тестовой-выборке-и-сравнение-с-константной-моделью-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Проверка на тестовой выборке и сравнение с константной моделью</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYYjS2uV8G0h"
      },
      "source": [
        "# Проект для «Викишоп»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4LiiB_J8G0h"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели.\n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM9fC7Ml8G0h"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nghTYJ_H8G0h"
      },
      "source": [
        "### Изучение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j871DSjF8G0h"
      },
      "outputs": [],
      "source": [
        "#импортируем необходимые для работы библиотеки\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "import catboost\n",
        "import lightgbm\n",
        "from sklearn.dummy import DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U5CBAEX8G0i"
      },
      "outputs": [],
      "source": [
        "#считаем датасет и сохраним его в переменной\n",
        "\n",
        "pth1 = '/content/toxic_comments.csv'\n",
        "pth2 = '/datasets/toxic_comments.csv'\n",
        "\n",
        "if os.path.exists(pth1):\n",
        "    data = pd.read_csv(pth1)\n",
        "elif os.path.exists(pth2):\n",
        "    data = pd.read_csv(pth2)\n",
        "else:\n",
        "    print('Ошибка')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TeX7zSNq8G0i",
        "outputId": "1e93d1d2-cee1-4ff4-fa64-701f111c1d56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1           1  D'aww! He matches this background colour I'm s...      0\n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4           4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head() #выведем первые 5 строк получившегося датафрейма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLrEI9jp8G0j",
        "outputId": "e4e246e2-2b0b-48c9-fa2b-fe27fa5e4584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  159292 non-null  int64 \n",
            " 1   text        159292 non-null  object\n",
            " 2   toxic       159292 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.6+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info() #теперь выведем основную информацию о датафрейме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "m2Q4LUlY8G0j",
        "outputId": "2f490f8f-72df-4c57-8306-01ea7ec358bd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#посмотрим на соотношение классов в целевом признаке\n",
        "f, ax = plt.subplots(figsize=(5, 5))\n",
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x=data['toxic'], color='m').set(title='Соотношение классов в целевом признаке')\n",
        "ax.set(ylabel=\"Количество\", xlabel=\"Классы\")\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjI6dHJx8G0j"
      },
      "source": [
        "Как мы видим, большинство комментариев - позитивные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWdAMTH88G0j"
      },
      "source": [
        "### Подготовка к машинному обучению"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svVKBkH38G0j",
        "outputId": "8a60c7ab-3eb6-4bed-9f18-99457b21ef73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text\n",
            "0  The striped bats are hanging on their feet for...\n",
            "1      you should be ashamed of yourself went worked\n",
            "0    the stripe bat be hang on their foot for good\n",
            "1        you should be ashamed of yourself go work\n",
            "Name: text, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#лемматизируем тексты\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatize(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_output = \" \".join([token.lemma_ for token in doc])\n",
        "    return lemmatized_output\n",
        "\n",
        "#проверим, что лемматизация проходит успешно, на тестовых предложениях\n",
        "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
        "sentence2 = \"you should be ashamed of yourself went worked\"\n",
        "df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
        "print(df_my)\n",
        "\n",
        "\n",
        "print(df_my['text'].apply(lemmatize))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIufX4dsI6MN",
        "outputId": "84e646b6-f911-4c8a-d1ae-0df469ddb04c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159292/159292 [18:29<00:00, 143.54it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>Explanation \\n why the edit make under my user...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>D'aww ! he match this background colour I be s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man , I be really not try to edit war . it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" \\n More \\n I can not make any real suggestio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you , sir , be my hero . any chance you rememb...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic  \\\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1           1  D'aww! He matches this background colour I'm s...      0   \n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  Explanation \\n why the edit make under my user...  \n",
              "1  D'aww ! he match this background colour I be s...  \n",
              "2  hey man , I be really not try to edit war . it...  \n",
              "3  \" \\n More \\n I can not make any real suggestio...  \n",
              "4  you , sir , be my hero . any chance you rememb...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#лемматизация тестовых предложений прошла успешно, применим нашу функцию ко всему датафрейму\n",
        "\n",
        "tqdm.pandas()\n",
        "data['lemm_text'] = data['text'].progress_apply(lemmatize)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHQ4AHvY8G0j",
        "outputId": "d3323090-15bd-4059-87cd-7cec841dfe55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>Explanation \\n why the edit make under my user...</td>\n",
              "      <td>Explanation why the edit make under my usernam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>D'aww ! he match this background colour I be s...</td>\n",
              "      <td>D aww he match this background colour I be see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man , I be really not try to edit war . it...</td>\n",
              "      <td>hey man I be really not try to edit war it be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" \\n More \\n I can not make any real suggestio...</td>\n",
              "      <td>More I can not make any real suggestion on imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you , sir , be my hero . any chance you rememb...</td>\n",
              "      <td>you sir be my hero any chance you remember wha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic  \\\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1           1  D'aww! He matches this background colour I'm s...      0   \n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \\\n",
              "0  Explanation \\n why the edit make under my user...   \n",
              "1  D'aww ! he match this background colour I be s...   \n",
              "2  hey man , I be really not try to edit war . it...   \n",
              "3  \" \\n More \\n I can not make any real suggestio...   \n",
              "4  you , sir , be my hero . any chance you rememb...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  Explanation why the edit make under my usernam...  \n",
              "1  D aww he match this background colour I be see...  \n",
              "2  hey man I be really not try to edit war it be ...  \n",
              "3  More I can not make any real suggestion on imp...  \n",
              "4  you sir be my hero any chance you remember wha...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#очистим тексты от лиших символов с помощью регулярных выражений\n",
        "\n",
        "def clear_text(text):\n",
        "    clear_text = re.sub(r'[^a-zA-z ]', ' ', text)\n",
        "    clear_text = \" \".join(clear_text.split())\n",
        "\n",
        "    return clear_text\n",
        "\n",
        "data['clean_text'] = data['lemm_text'].apply(clear_text)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nzFkcON8G0k"
      },
      "outputs": [],
      "source": [
        "#далее разделим датафрейм на обучающую и тестовую выборки\n",
        "features_train, features_test, target_train, target_test = train_test_split(data['clean_text'], data['toxic'],\n",
        "                                                                            test_size=0.25,\n",
        "                                                                            random_state=12345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcMwscq8G0k"
      },
      "source": [
        "**Вывод:** мы считали исходный датасет и изучили его, а также подготовили данные для дальнейшего обучения: лемматизировали, очистили тексты от лишних символов, разделили датафрейм на обучающую и тестовую выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDRVm-iX8G0k"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Aew5-Re8G0k"
      },
      "source": [
        "Обучим три модели: логистическую регрессию, CatBoost и LightGBM. Выбирать лучшие значения гиперпараметров будем с помощью GridSearchCV. По условиям исследования для оценки качества моделей необходимо использовать метрику F1, и её значение должно быть не меньше 0.75."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XDuefrxI6MO",
        "outputId": "6ae7028a-93a0-425d-dab3-f96e5c277ffd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#инициализируем пайплайн для обучения моделей: он будет векторизовать тексты, обучать модели\n",
        "#а также с помощью GridSearchCV подбирать гиперпараметры\n",
        "nltk.download('stopwords')\n",
        "stop_list = list(stopwords.words('english'))\n",
        "\n",
        "def training(model, params):\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words=stop_list, decode_error='ignore')),\n",
        "        ('model', model)])\n",
        "    grid = GridSearchCV(pipeline, cv = 3, n_jobs = -1, param_grid = params ,scoring = 'f1', verbose = 1)\n",
        "    grid.fit(features_train, target_train)\n",
        "    print('Лучший результат F1:', grid.best_score_)\n",
        "    print('Лучшие гиперпараметры:', grid.best_params_)\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvP-kMcL8G0k"
      },
      "source": [
        "### Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "BnVrvoeNI6MO",
        "outputId": "7928167a-76cd-4086-9c8f-e2f0dfa81fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучший результат F1: 0.7733771909698653\n",
            "Лучшие гиперпараметры: {'model__C': 6, 'model__penalty': 'l1'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        }
      ],
      "source": [
        "model_lr = training(LogisticRegression(solver='saga'), {\"model__C\": np.arange(5, 15), \"model__penalty\": ['l1', 'l2']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jjZbaSR8G0k"
      },
      "source": [
        "### CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "i8DE3WUAI6MP",
        "outputId": "d4a4a4c3-b3f1-47e8-aca8-f5e9a1137101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "0:\tlearn: 0.6823259\ttotal: 968ms\tremaining: 8.71s\n",
            "1:\tlearn: 0.6722235\ttotal: 1.89s\tremaining: 7.58s\n",
            "2:\tlearn: 0.6623275\ttotal: 2.79s\tremaining: 6.51s\n",
            "3:\tlearn: 0.6523453\ttotal: 3.67s\tremaining: 5.51s\n",
            "4:\tlearn: 0.6428623\ttotal: 4.64s\tremaining: 4.64s\n",
            "5:\tlearn: 0.6333432\ttotal: 5.59s\tremaining: 3.73s\n",
            "6:\tlearn: 0.6243545\ttotal: 6.54s\tremaining: 2.8s\n",
            "7:\tlearn: 0.6156901\ttotal: 7.42s\tremaining: 1.86s\n",
            "8:\tlearn: 0.6067841\ttotal: 8.35s\tremaining: 928ms\n",
            "9:\tlearn: 0.5982984\ttotal: 9.27s\tremaining: 0us\n",
            "0:\tlearn: 0.6825103\ttotal: 962ms\tremaining: 8.66s\n",
            "1:\tlearn: 0.6721447\ttotal: 1.97s\tremaining: 7.88s\n",
            "2:\tlearn: 0.6617636\ttotal: 2.96s\tremaining: 6.9s\n",
            "3:\tlearn: 0.6523942\ttotal: 3.95s\tremaining: 5.92s\n",
            "4:\tlearn: 0.6434222\ttotal: 4.85s\tremaining: 4.85s\n",
            "5:\tlearn: 0.6340633\ttotal: 5.8s\tremaining: 3.86s\n",
            "6:\tlearn: 0.6245342\ttotal: 6.74s\tremaining: 2.89s\n",
            "7:\tlearn: 0.6157720\ttotal: 7.65s\tremaining: 1.91s\n",
            "8:\tlearn: 0.6068930\ttotal: 8.61s\tremaining: 957ms\n",
            "9:\tlearn: 0.5987500\ttotal: 9.55s\tremaining: 0us\n",
            "0:\tlearn: 0.6824289\ttotal: 926ms\tremaining: 8.33s\n",
            "1:\tlearn: 0.6717229\ttotal: 1.88s\tremaining: 7.53s\n",
            "2:\tlearn: 0.6614864\ttotal: 2.85s\tremaining: 6.64s\n",
            "3:\tlearn: 0.6515225\ttotal: 3.73s\tremaining: 5.6s\n",
            "4:\tlearn: 0.6420654\ttotal: 4.63s\tremaining: 4.63s\n",
            "5:\tlearn: 0.6326477\ttotal: 5.55s\tremaining: 3.7s\n",
            "6:\tlearn: 0.6233401\ttotal: 6.43s\tremaining: 2.75s\n",
            "7:\tlearn: 0.6147346\ttotal: 7.35s\tremaining: 1.84s\n",
            "8:\tlearn: 0.6059877\ttotal: 8.28s\tremaining: 920ms\n",
            "9:\tlearn: 0.5975766\ttotal: 9.23s\tremaining: 0us\n",
            "0:\tlearn: 0.6413435\ttotal: 935ms\tremaining: 8.41s\n",
            "1:\tlearn: 0.5963778\ttotal: 1.85s\tremaining: 7.41s\n",
            "2:\tlearn: 0.5569968\ttotal: 2.78s\tremaining: 6.5s\n",
            "3:\tlearn: 0.5220554\ttotal: 3.72s\tremaining: 5.58s\n",
            "4:\tlearn: 0.4912322\ttotal: 4.7s\tremaining: 4.7s\n",
            "5:\tlearn: 0.4631930\ttotal: 5.65s\tremaining: 3.77s\n",
            "6:\tlearn: 0.4391611\ttotal: 6.6s\tremaining: 2.83s\n",
            "7:\tlearn: 0.4168426\ttotal: 7.54s\tremaining: 1.89s\n",
            "8:\tlearn: 0.3974871\ttotal: 8.48s\tremaining: 943ms\n",
            "9:\tlearn: 0.3811633\ttotal: 9.41s\tremaining: 0us\n",
            "0:\tlearn: 0.6419012\ttotal: 953ms\tremaining: 8.57s\n",
            "1:\tlearn: 0.5960611\ttotal: 1.86s\tremaining: 7.45s\n",
            "2:\tlearn: 0.5550631\ttotal: 2.78s\tremaining: 6.49s\n",
            "3:\tlearn: 0.5203497\ttotal: 3.76s\tremaining: 5.63s\n",
            "4:\tlearn: 0.4890676\ttotal: 4.69s\tremaining: 4.69s\n",
            "5:\tlearn: 0.4626655\ttotal: 5.65s\tremaining: 3.77s\n",
            "6:\tlearn: 0.4375446\ttotal: 6.64s\tremaining: 2.85s\n",
            "7:\tlearn: 0.4160526\ttotal: 7.6s\tremaining: 1.9s\n",
            "8:\tlearn: 0.3969388\ttotal: 8.6s\tremaining: 956ms\n",
            "9:\tlearn: 0.3803065\ttotal: 9.62s\tremaining: 0us\n",
            "0:\tlearn: 0.6415008\ttotal: 897ms\tremaining: 8.07s\n",
            "1:\tlearn: 0.5947878\ttotal: 1.84s\tremaining: 7.36s\n",
            "2:\tlearn: 0.5539993\ttotal: 2.75s\tremaining: 6.41s\n",
            "3:\tlearn: 0.5189325\ttotal: 3.66s\tremaining: 5.49s\n",
            "4:\tlearn: 0.4886294\ttotal: 4.58s\tremaining: 4.58s\n",
            "5:\tlearn: 0.4612818\ttotal: 5.55s\tremaining: 3.7s\n",
            "6:\tlearn: 0.4368186\ttotal: 6.48s\tremaining: 2.78s\n",
            "7:\tlearn: 0.4150799\ttotal: 7.36s\tremaining: 1.84s\n",
            "8:\tlearn: 0.3966810\ttotal: 8.2s\tremaining: 911ms\n",
            "9:\tlearn: 0.3796002\ttotal: 9.07s\tremaining: 0us\n",
            "0:\tlearn: 0.6823259\ttotal: 874ms\tremaining: 42.8s\n",
            "1:\tlearn: 0.6722235\ttotal: 1.78s\tremaining: 42.7s\n",
            "2:\tlearn: 0.6623275\ttotal: 2.61s\tremaining: 40.9s\n",
            "3:\tlearn: 0.6523453\ttotal: 3.47s\tremaining: 39.9s\n",
            "4:\tlearn: 0.6428623\ttotal: 4.36s\tremaining: 39.2s\n",
            "5:\tlearn: 0.6333432\ttotal: 5.22s\tremaining: 38.3s\n",
            "6:\tlearn: 0.6243545\ttotal: 6.04s\tremaining: 37.1s\n",
            "7:\tlearn: 0.6156901\ttotal: 6.89s\tremaining: 36.2s\n",
            "8:\tlearn: 0.6067841\ttotal: 7.79s\tremaining: 35.5s\n",
            "9:\tlearn: 0.5982984\ttotal: 8.64s\tremaining: 34.6s\n",
            "10:\tlearn: 0.5896030\ttotal: 9.54s\tremaining: 33.8s\n",
            "11:\tlearn: 0.5819803\ttotal: 10.4s\tremaining: 33s\n",
            "12:\tlearn: 0.5741437\ttotal: 11.3s\tremaining: 32.2s\n",
            "13:\tlearn: 0.5665717\ttotal: 12.2s\tremaining: 31.3s\n",
            "14:\tlearn: 0.5588798\ttotal: 13.1s\tremaining: 30.5s\n",
            "15:\tlearn: 0.5514158\ttotal: 14s\tremaining: 29.7s\n",
            "16:\tlearn: 0.5443729\ttotal: 14.8s\tremaining: 28.8s\n",
            "17:\tlearn: 0.5373392\ttotal: 15.7s\tremaining: 27.9s\n",
            "18:\tlearn: 0.5304925\ttotal: 16.6s\tremaining: 27s\n",
            "19:\tlearn: 0.5239158\ttotal: 17.5s\tremaining: 26.2s\n",
            "20:\tlearn: 0.5176568\ttotal: 18.3s\tremaining: 25.3s\n",
            "21:\tlearn: 0.5112464\ttotal: 19.2s\tremaining: 24.4s\n",
            "22:\tlearn: 0.5048320\ttotal: 20.1s\tremaining: 23.6s\n",
            "23:\tlearn: 0.4987338\ttotal: 21s\tremaining: 22.7s\n",
            "24:\tlearn: 0.4927900\ttotal: 21.9s\tremaining: 21.9s\n",
            "25:\tlearn: 0.4869395\ttotal: 22.7s\tremaining: 21s\n",
            "26:\tlearn: 0.4812744\ttotal: 23.6s\tremaining: 20.1s\n",
            "27:\tlearn: 0.4759878\ttotal: 24.4s\tremaining: 19.2s\n",
            "28:\tlearn: 0.4707426\ttotal: 25.3s\tremaining: 18.3s\n",
            "29:\tlearn: 0.4655939\ttotal: 26.2s\tremaining: 17.5s\n",
            "30:\tlearn: 0.4602958\ttotal: 27s\tremaining: 16.6s\n",
            "31:\tlearn: 0.4552261\ttotal: 28s\tremaining: 15.7s\n",
            "32:\tlearn: 0.4504127\ttotal: 28.8s\tremaining: 14.9s\n",
            "33:\tlearn: 0.4458077\ttotal: 29.7s\tremaining: 14s\n",
            "34:\tlearn: 0.4410965\ttotal: 30.6s\tremaining: 13.1s\n",
            "35:\tlearn: 0.4365488\ttotal: 31.5s\tremaining: 12.3s\n",
            "36:\tlearn: 0.4319736\ttotal: 32.4s\tremaining: 11.4s\n",
            "37:\tlearn: 0.4277571\ttotal: 33.3s\tremaining: 10.5s\n",
            "38:\tlearn: 0.4235426\ttotal: 34.2s\tremaining: 9.64s\n",
            "39:\tlearn: 0.4193459\ttotal: 35.1s\tremaining: 8.76s\n",
            "40:\tlearn: 0.4154123\ttotal: 35.9s\tremaining: 7.89s\n",
            "41:\tlearn: 0.4115266\ttotal: 36.8s\tremaining: 7.01s\n",
            "42:\tlearn: 0.4075285\ttotal: 37.7s\tremaining: 6.13s\n",
            "43:\tlearn: 0.4037483\ttotal: 38.6s\tremaining: 5.26s\n",
            "44:\tlearn: 0.4002214\ttotal: 39.5s\tremaining: 4.39s\n",
            "45:\tlearn: 0.3965403\ttotal: 40.4s\tremaining: 3.51s\n",
            "46:\tlearn: 0.3930902\ttotal: 41.4s\tremaining: 2.64s\n",
            "47:\tlearn: 0.3897037\ttotal: 42.3s\tremaining: 1.76s\n",
            "48:\tlearn: 0.3863993\ttotal: 43.1s\tremaining: 880ms\n",
            "49:\tlearn: 0.3831314\ttotal: 44s\tremaining: 0us\n",
            "0:\tlearn: 0.6825103\ttotal: 872ms\tremaining: 42.7s\n",
            "1:\tlearn: 0.6721447\ttotal: 1.81s\tremaining: 43.6s\n",
            "2:\tlearn: 0.6617636\ttotal: 2.76s\tremaining: 43.3s\n",
            "3:\tlearn: 0.6523942\ttotal: 3.67s\tremaining: 42.2s\n",
            "4:\tlearn: 0.6434222\ttotal: 4.5s\tremaining: 40.5s\n",
            "5:\tlearn: 0.6340633\ttotal: 5.37s\tremaining: 39.4s\n",
            "6:\tlearn: 0.6245342\ttotal: 6.25s\tremaining: 38.4s\n",
            "7:\tlearn: 0.6157720\ttotal: 7.09s\tremaining: 37.2s\n",
            "8:\tlearn: 0.6068930\ttotal: 7.96s\tremaining: 36.3s\n",
            "9:\tlearn: 0.5987500\ttotal: 8.83s\tremaining: 35.3s\n",
            "10:\tlearn: 0.5904016\ttotal: 9.69s\tremaining: 34.4s\n",
            "11:\tlearn: 0.5824335\ttotal: 10.6s\tremaining: 33.4s\n",
            "12:\tlearn: 0.5744914\ttotal: 11.4s\tremaining: 32.5s\n",
            "13:\tlearn: 0.5667562\ttotal: 12.3s\tremaining: 31.7s\n",
            "14:\tlearn: 0.5589468\ttotal: 13.2s\tremaining: 30.9s\n",
            "15:\tlearn: 0.5519688\ttotal: 14.1s\tremaining: 30s\n",
            "16:\tlearn: 0.5446769\ttotal: 15s\tremaining: 29.1s\n",
            "17:\tlearn: 0.5374142\ttotal: 15.9s\tremaining: 28.3s\n",
            "18:\tlearn: 0.5307298\ttotal: 16.8s\tremaining: 27.4s\n",
            "19:\tlearn: 0.5240396\ttotal: 17.6s\tremaining: 26.4s\n",
            "20:\tlearn: 0.5175327\ttotal: 18.5s\tremaining: 25.6s\n",
            "21:\tlearn: 0.5113295\ttotal: 19.4s\tremaining: 24.7s\n",
            "22:\tlearn: 0.5052199\ttotal: 20.2s\tremaining: 23.8s\n",
            "23:\tlearn: 0.4990983\ttotal: 21.1s\tremaining: 22.9s\n",
            "24:\tlearn: 0.4932865\ttotal: 22s\tremaining: 22s\n",
            "25:\tlearn: 0.4874745\ttotal: 22.9s\tremaining: 21.2s\n",
            "26:\tlearn: 0.4819347\ttotal: 23.9s\tremaining: 20.3s\n",
            "27:\tlearn: 0.4767345\ttotal: 24.8s\tremaining: 19.4s\n",
            "28:\tlearn: 0.4714080\ttotal: 25.6s\tremaining: 18.6s\n",
            "29:\tlearn: 0.4662482\ttotal: 26.5s\tremaining: 17.7s\n",
            "30:\tlearn: 0.4610508\ttotal: 27.4s\tremaining: 16.8s\n",
            "31:\tlearn: 0.4560952\ttotal: 28.3s\tremaining: 15.9s\n",
            "32:\tlearn: 0.4512989\ttotal: 29.2s\tremaining: 15s\n",
            "33:\tlearn: 0.4463574\ttotal: 30.1s\tremaining: 14.2s\n",
            "34:\tlearn: 0.4417885\ttotal: 30.9s\tremaining: 13.3s\n",
            "35:\tlearn: 0.4373282\ttotal: 31.9s\tremaining: 12.4s\n",
            "36:\tlearn: 0.4328568\ttotal: 32.8s\tremaining: 11.5s\n",
            "37:\tlearn: 0.4285539\ttotal: 33.7s\tremaining: 10.6s\n",
            "38:\tlearn: 0.4243333\ttotal: 34.6s\tremaining: 9.76s\n",
            "39:\tlearn: 0.4201871\ttotal: 35.5s\tremaining: 8.87s\n",
            "40:\tlearn: 0.4162737\ttotal: 36.4s\tremaining: 7.98s\n",
            "41:\tlearn: 0.4121984\ttotal: 37.3s\tremaining: 7.1s\n",
            "42:\tlearn: 0.4083950\ttotal: 38.2s\tremaining: 6.22s\n",
            "43:\tlearn: 0.4046852\ttotal: 39.1s\tremaining: 5.33s\n",
            "44:\tlearn: 0.4012433\ttotal: 40s\tremaining: 4.45s\n",
            "45:\tlearn: 0.3978924\ttotal: 40.9s\tremaining: 3.55s\n",
            "46:\tlearn: 0.3942731\ttotal: 41.7s\tremaining: 2.66s\n",
            "47:\tlearn: 0.3910203\ttotal: 42.6s\tremaining: 1.78s\n",
            "48:\tlearn: 0.3878284\ttotal: 43.6s\tremaining: 890ms\n",
            "49:\tlearn: 0.3845688\ttotal: 44.5s\tremaining: 0us\n",
            "0:\tlearn: 0.6824289\ttotal: 832ms\tremaining: 40.8s\n",
            "1:\tlearn: 0.6717229\ttotal: 1.69s\tremaining: 40.5s\n",
            "2:\tlearn: 0.6614864\ttotal: 2.57s\tremaining: 40.2s\n",
            "3:\tlearn: 0.6515225\ttotal: 3.4s\tremaining: 39.1s\n",
            "4:\tlearn: 0.6420654\ttotal: 4.27s\tremaining: 38.5s\n",
            "5:\tlearn: 0.6326477\ttotal: 5.19s\tremaining: 38.1s\n",
            "6:\tlearn: 0.6233401\ttotal: 6.09s\tremaining: 37.4s\n",
            "7:\tlearn: 0.6147346\ttotal: 6.96s\tremaining: 36.5s\n",
            "8:\tlearn: 0.6059877\ttotal: 7.83s\tremaining: 35.7s\n",
            "9:\tlearn: 0.5975766\ttotal: 8.69s\tremaining: 34.8s\n",
            "10:\tlearn: 0.5891665\ttotal: 9.55s\tremaining: 33.9s\n",
            "11:\tlearn: 0.5812289\ttotal: 10.4s\tremaining: 32.9s\n",
            "12:\tlearn: 0.5733401\ttotal: 11.3s\tremaining: 32.1s\n",
            "13:\tlearn: 0.5658556\ttotal: 12.1s\tremaining: 31.2s\n",
            "14:\tlearn: 0.5581798\ttotal: 13s\tremaining: 30.4s\n",
            "15:\tlearn: 0.5511121\ttotal: 13.9s\tremaining: 29.6s\n",
            "16:\tlearn: 0.5440563\ttotal: 14.8s\tremaining: 28.8s\n",
            "17:\tlearn: 0.5372217\ttotal: 15.8s\tremaining: 28.1s\n",
            "18:\tlearn: 0.5302152\ttotal: 16.7s\tremaining: 27.3s\n",
            "19:\tlearn: 0.5233821\ttotal: 17.6s\tremaining: 26.4s\n",
            "20:\tlearn: 0.5170357\ttotal: 18.5s\tremaining: 25.5s\n",
            "21:\tlearn: 0.5105624\ttotal: 19.4s\tremaining: 24.6s\n",
            "22:\tlearn: 0.5044305\ttotal: 20.2s\tremaining: 23.8s\n",
            "23:\tlearn: 0.4981887\ttotal: 21.1s\tremaining: 22.9s\n",
            "24:\tlearn: 0.4925299\ttotal: 22s\tremaining: 22s\n",
            "25:\tlearn: 0.4867881\ttotal: 22.9s\tremaining: 21.1s\n",
            "26:\tlearn: 0.4810944\ttotal: 23.8s\tremaining: 20.3s\n",
            "27:\tlearn: 0.4756363\ttotal: 24.7s\tremaining: 19.4s\n",
            "28:\tlearn: 0.4702962\ttotal: 25.6s\tremaining: 18.6s\n",
            "29:\tlearn: 0.4650571\ttotal: 26.5s\tremaining: 17.7s\n",
            "30:\tlearn: 0.4596453\ttotal: 27.4s\tremaining: 16.8s\n",
            "31:\tlearn: 0.4546281\ttotal: 28.3s\tremaining: 15.9s\n",
            "32:\tlearn: 0.4497354\ttotal: 29.2s\tremaining: 15s\n",
            "33:\tlearn: 0.4447930\ttotal: 30.1s\tremaining: 14.2s\n",
            "34:\tlearn: 0.4403997\ttotal: 30.9s\tremaining: 13.3s\n",
            "35:\tlearn: 0.4359188\ttotal: 31.8s\tremaining: 12.4s\n",
            "36:\tlearn: 0.4313964\ttotal: 32.7s\tremaining: 11.5s\n",
            "37:\tlearn: 0.4270811\ttotal: 33.6s\tremaining: 10.6s\n",
            "38:\tlearn: 0.4229044\ttotal: 34.5s\tremaining: 9.73s\n",
            "39:\tlearn: 0.4187251\ttotal: 35.5s\tremaining: 8.87s\n",
            "40:\tlearn: 0.4148792\ttotal: 36.4s\tremaining: 7.98s\n",
            "41:\tlearn: 0.4110687\ttotal: 37.3s\tremaining: 7.1s\n",
            "42:\tlearn: 0.4072363\ttotal: 38.2s\tremaining: 6.21s\n",
            "43:\tlearn: 0.4035566\ttotal: 39s\tremaining: 5.33s\n",
            "44:\tlearn: 0.3998382\ttotal: 39.9s\tremaining: 4.44s\n",
            "45:\tlearn: 0.3963690\ttotal: 40.8s\tremaining: 3.55s\n",
            "46:\tlearn: 0.3930041\ttotal: 41.7s\tremaining: 2.66s\n",
            "47:\tlearn: 0.3896351\ttotal: 42.5s\tremaining: 1.77s\n",
            "48:\tlearn: 0.3863808\ttotal: 43.4s\tremaining: 886ms\n",
            "49:\tlearn: 0.3832294\ttotal: 44.3s\tremaining: 0us\n",
            "0:\tlearn: 0.6413435\ttotal: 896ms\tremaining: 43.9s\n",
            "1:\tlearn: 0.5963778\ttotal: 1.78s\tremaining: 42.8s\n",
            "2:\tlearn: 0.5569968\ttotal: 2.65s\tremaining: 41.5s\n",
            "3:\tlearn: 0.5220554\ttotal: 3.57s\tremaining: 41.1s\n",
            "4:\tlearn: 0.4912322\ttotal: 4.52s\tremaining: 40.6s\n",
            "5:\tlearn: 0.4631930\ttotal: 5.48s\tremaining: 40.2s\n",
            "6:\tlearn: 0.4391611\ttotal: 6.51s\tremaining: 40s\n",
            "7:\tlearn: 0.4168426\ttotal: 7.49s\tremaining: 39.3s\n",
            "8:\tlearn: 0.3974871\ttotal: 8.44s\tremaining: 38.5s\n",
            "9:\tlearn: 0.3811633\ttotal: 9.35s\tremaining: 37.4s\n",
            "10:\tlearn: 0.3663750\ttotal: 10.3s\tremaining: 36.5s\n",
            "11:\tlearn: 0.3529654\ttotal: 11.4s\tremaining: 36.1s\n",
            "12:\tlearn: 0.3413382\ttotal: 12.3s\tremaining: 35s\n",
            "13:\tlearn: 0.3304184\ttotal: 13.2s\tremaining: 34s\n",
            "14:\tlearn: 0.3210943\ttotal: 14.1s\tremaining: 33s\n",
            "15:\tlearn: 0.3127122\ttotal: 15.1s\tremaining: 32s\n",
            "16:\tlearn: 0.3051766\ttotal: 16.1s\tremaining: 31.2s\n",
            "17:\tlearn: 0.2983662\ttotal: 17.1s\tremaining: 30.4s\n",
            "18:\tlearn: 0.2921357\ttotal: 18.1s\tremaining: 29.5s\n",
            "19:\tlearn: 0.2868355\ttotal: 19.1s\tremaining: 28.6s\n",
            "20:\tlearn: 0.2817992\ttotal: 20s\tremaining: 27.6s\n",
            "21:\tlearn: 0.2773195\ttotal: 21s\tremaining: 26.7s\n",
            "22:\tlearn: 0.2732240\ttotal: 21.9s\tremaining: 25.7s\n",
            "23:\tlearn: 0.2686391\ttotal: 22.8s\tremaining: 24.8s\n",
            "24:\tlearn: 0.2650716\ttotal: 23.7s\tremaining: 23.7s\n",
            "25:\tlearn: 0.2621036\ttotal: 24.6s\tremaining: 22.7s\n",
            "26:\tlearn: 0.2589585\ttotal: 25.5s\tremaining: 21.7s\n",
            "27:\tlearn: 0.2561647\ttotal: 26.4s\tremaining: 20.8s\n",
            "28:\tlearn: 0.2537141\ttotal: 27.4s\tremaining: 19.8s\n",
            "29:\tlearn: 0.2516604\ttotal: 28.2s\tremaining: 18.8s\n",
            "30:\tlearn: 0.2495881\ttotal: 29.1s\tremaining: 17.8s\n",
            "31:\tlearn: 0.2476542\ttotal: 30s\tremaining: 16.9s\n",
            "32:\tlearn: 0.2457322\ttotal: 30.9s\tremaining: 15.9s\n",
            "33:\tlearn: 0.2439829\ttotal: 31.8s\tremaining: 14.9s\n",
            "34:\tlearn: 0.2423137\ttotal: 32.7s\tremaining: 14s\n",
            "35:\tlearn: 0.2410291\ttotal: 33.5s\tremaining: 13s\n",
            "36:\tlearn: 0.2394536\ttotal: 34.4s\tremaining: 12.1s\n",
            "37:\tlearn: 0.2381574\ttotal: 35.4s\tremaining: 11.2s\n",
            "38:\tlearn: 0.2367770\ttotal: 36.3s\tremaining: 10.2s\n",
            "39:\tlearn: 0.2351815\ttotal: 37.3s\tremaining: 9.32s\n",
            "40:\tlearn: 0.2339609\ttotal: 38.1s\tremaining: 8.37s\n",
            "41:\tlearn: 0.2328904\ttotal: 39s\tremaining: 7.43s\n",
            "42:\tlearn: 0.2318142\ttotal: 39.9s\tremaining: 6.49s\n",
            "43:\tlearn: 0.2307641\ttotal: 40.7s\tremaining: 5.55s\n",
            "44:\tlearn: 0.2297663\ttotal: 41.6s\tremaining: 4.62s\n",
            "45:\tlearn: 0.2284944\ttotal: 42.5s\tremaining: 3.7s\n",
            "46:\tlearn: 0.2276201\ttotal: 43.4s\tremaining: 2.77s\n",
            "47:\tlearn: 0.2264989\ttotal: 44.3s\tremaining: 1.85s\n",
            "48:\tlearn: 0.2256070\ttotal: 45.2s\tremaining: 922ms\n",
            "49:\tlearn: 0.2248188\ttotal: 46.1s\tremaining: 0us\n",
            "0:\tlearn: 0.6419012\ttotal: 878ms\tremaining: 43s\n",
            "1:\tlearn: 0.5960611\ttotal: 1.79s\tremaining: 42.9s\n",
            "2:\tlearn: 0.5550631\ttotal: 2.68s\tremaining: 42.1s\n",
            "3:\tlearn: 0.5203497\ttotal: 3.56s\tremaining: 40.9s\n",
            "4:\tlearn: 0.4890676\ttotal: 4.47s\tremaining: 40.3s\n",
            "5:\tlearn: 0.4626655\ttotal: 5.36s\tremaining: 39.3s\n",
            "6:\tlearn: 0.4375446\ttotal: 6.25s\tremaining: 38.4s\n",
            "7:\tlearn: 0.4160526\ttotal: 7.21s\tremaining: 37.8s\n",
            "8:\tlearn: 0.3969388\ttotal: 8.11s\tremaining: 37s\n",
            "9:\tlearn: 0.3803065\ttotal: 9.03s\tremaining: 36.1s\n",
            "10:\tlearn: 0.3656697\ttotal: 9.91s\tremaining: 35.1s\n",
            "11:\tlearn: 0.3525441\ttotal: 10.8s\tremaining: 34.2s\n",
            "12:\tlearn: 0.3409281\ttotal: 11.7s\tremaining: 33.2s\n",
            "13:\tlearn: 0.3307534\ttotal: 12.6s\tremaining: 32.4s\n",
            "14:\tlearn: 0.3216527\ttotal: 13.5s\tremaining: 31.5s\n",
            "15:\tlearn: 0.3131789\ttotal: 14.4s\tremaining: 30.6s\n",
            "16:\tlearn: 0.3058447\ttotal: 15.3s\tremaining: 29.7s\n",
            "17:\tlearn: 0.2990367\ttotal: 16.2s\tremaining: 28.8s\n",
            "18:\tlearn: 0.2927975\ttotal: 17.2s\tremaining: 28s\n",
            "19:\tlearn: 0.2872059\ttotal: 18.1s\tremaining: 27.1s\n",
            "20:\tlearn: 0.2821788\ttotal: 19s\tremaining: 26.2s\n",
            "21:\tlearn: 0.2773939\ttotal: 19.9s\tremaining: 25.3s\n",
            "22:\tlearn: 0.2733273\ttotal: 20.7s\tremaining: 24.4s\n",
            "23:\tlearn: 0.2698551\ttotal: 21.6s\tremaining: 23.4s\n",
            "24:\tlearn: 0.2663320\ttotal: 22.5s\tremaining: 22.5s\n",
            "25:\tlearn: 0.2631126\ttotal: 23.4s\tremaining: 21.6s\n",
            "26:\tlearn: 0.2599710\ttotal: 24.3s\tremaining: 20.7s\n",
            "27:\tlearn: 0.2572341\ttotal: 25.2s\tremaining: 19.8s\n",
            "28:\tlearn: 0.2544181\ttotal: 26.1s\tremaining: 18.9s\n",
            "29:\tlearn: 0.2517958\ttotal: 27s\tremaining: 18s\n",
            "30:\tlearn: 0.2497802\ttotal: 27.9s\tremaining: 17.1s\n",
            "31:\tlearn: 0.2477981\ttotal: 28.8s\tremaining: 16.2s\n",
            "32:\tlearn: 0.2460262\ttotal: 29.7s\tremaining: 15.3s\n",
            "33:\tlearn: 0.2442597\ttotal: 30.6s\tremaining: 14.4s\n",
            "34:\tlearn: 0.2426627\ttotal: 31.4s\tremaining: 13.5s\n",
            "35:\tlearn: 0.2412019\ttotal: 32.3s\tremaining: 12.6s\n",
            "36:\tlearn: 0.2399114\ttotal: 33.2s\tremaining: 11.7s\n",
            "37:\tlearn: 0.2386868\ttotal: 34.1s\tremaining: 10.8s\n",
            "38:\tlearn: 0.2375712\ttotal: 35s\tremaining: 9.88s\n",
            "39:\tlearn: 0.2364189\ttotal: 35.9s\tremaining: 8.98s\n",
            "40:\tlearn: 0.2349603\ttotal: 36.9s\tremaining: 8.1s\n",
            "41:\tlearn: 0.2337569\ttotal: 37.8s\tremaining: 7.2s\n",
            "42:\tlearn: 0.2328321\ttotal: 38.7s\tremaining: 6.3s\n",
            "43:\tlearn: 0.2318751\ttotal: 39.6s\tremaining: 5.41s\n",
            "44:\tlearn: 0.2310809\ttotal: 40.5s\tremaining: 4.5s\n",
            "45:\tlearn: 0.2301523\ttotal: 41.4s\tremaining: 3.6s\n",
            "46:\tlearn: 0.2293243\ttotal: 42.3s\tremaining: 2.7s\n",
            "47:\tlearn: 0.2284790\ttotal: 43.2s\tremaining: 1.8s\n",
            "48:\tlearn: 0.2275393\ttotal: 44.1s\tremaining: 901ms\n",
            "49:\tlearn: 0.2264116\ttotal: 45.1s\tremaining: 0us\n",
            "0:\tlearn: 0.6415008\ttotal: 872ms\tremaining: 42.7s\n",
            "1:\tlearn: 0.5947878\ttotal: 1.76s\tremaining: 42.2s\n",
            "2:\tlearn: 0.5539993\ttotal: 2.64s\tremaining: 41.4s\n",
            "3:\tlearn: 0.5189325\ttotal: 3.51s\tremaining: 40.3s\n",
            "4:\tlearn: 0.4886294\ttotal: 4.41s\tremaining: 39.7s\n",
            "5:\tlearn: 0.4612818\ttotal: 5.29s\tremaining: 38.8s\n",
            "6:\tlearn: 0.4368186\ttotal: 6.22s\tremaining: 38.2s\n",
            "7:\tlearn: 0.4150799\ttotal: 7.16s\tremaining: 37.6s\n",
            "8:\tlearn: 0.3966810\ttotal: 8.07s\tremaining: 36.8s\n",
            "9:\tlearn: 0.3796002\ttotal: 8.95s\tremaining: 35.8s\n",
            "10:\tlearn: 0.3646451\ttotal: 9.84s\tremaining: 34.9s\n",
            "11:\tlearn: 0.3514678\ttotal: 10.7s\tremaining: 33.9s\n",
            "12:\tlearn: 0.3397484\ttotal: 11.6s\tremaining: 33s\n",
            "13:\tlearn: 0.3292301\ttotal: 12.5s\tremaining: 32.2s\n",
            "14:\tlearn: 0.3197917\ttotal: 13.4s\tremaining: 31.3s\n",
            "15:\tlearn: 0.3115125\ttotal: 14.3s\tremaining: 30.4s\n",
            "16:\tlearn: 0.3039112\ttotal: 15.2s\tremaining: 29.5s\n",
            "17:\tlearn: 0.2971971\ttotal: 16.2s\tremaining: 28.7s\n",
            "18:\tlearn: 0.2909414\ttotal: 17.1s\tremaining: 27.9s\n",
            "19:\tlearn: 0.2854255\ttotal: 18s\tremaining: 27.1s\n",
            "20:\tlearn: 0.2803452\ttotal: 18.9s\tremaining: 26.2s\n",
            "21:\tlearn: 0.2757400\ttotal: 19.9s\tremaining: 25.3s\n",
            "22:\tlearn: 0.2717824\ttotal: 20.7s\tremaining: 24.3s\n",
            "23:\tlearn: 0.2681867\ttotal: 21.6s\tremaining: 23.4s\n",
            "24:\tlearn: 0.2646708\ttotal: 22.5s\tremaining: 22.5s\n",
            "25:\tlearn: 0.2615459\ttotal: 23.4s\tremaining: 21.6s\n",
            "26:\tlearn: 0.2587280\ttotal: 24.3s\tremaining: 20.7s\n",
            "27:\tlearn: 0.2562112\ttotal: 25.2s\tremaining: 19.8s\n",
            "28:\tlearn: 0.2539756\ttotal: 26.1s\tremaining: 18.9s\n",
            "29:\tlearn: 0.2516725\ttotal: 27.1s\tremaining: 18.1s\n",
            "30:\tlearn: 0.2492207\ttotal: 28.1s\tremaining: 17.2s\n",
            "31:\tlearn: 0.2469121\ttotal: 29s\tremaining: 16.3s\n",
            "32:\tlearn: 0.2451659\ttotal: 29.8s\tremaining: 15.4s\n",
            "33:\tlearn: 0.2434670\ttotal: 30.7s\tremaining: 14.5s\n",
            "34:\tlearn: 0.2418931\ttotal: 31.6s\tremaining: 13.6s\n",
            "35:\tlearn: 0.2404333\ttotal: 32.5s\tremaining: 12.7s\n",
            "36:\tlearn: 0.2386798\ttotal: 33.4s\tremaining: 11.7s\n",
            "37:\tlearn: 0.2374164\ttotal: 34.3s\tremaining: 10.8s\n",
            "38:\tlearn: 0.2363198\ttotal: 35.2s\tremaining: 9.92s\n",
            "39:\tlearn: 0.2352349\ttotal: 36s\tremaining: 9.01s\n",
            "40:\tlearn: 0.2340831\ttotal: 37s\tremaining: 8.11s\n",
            "41:\tlearn: 0.2329889\ttotal: 37.9s\tremaining: 7.22s\n",
            "42:\tlearn: 0.2319029\ttotal: 38.8s\tremaining: 6.31s\n",
            "43:\tlearn: 0.2309933\ttotal: 39.6s\tremaining: 5.41s\n",
            "44:\tlearn: 0.2300298\ttotal: 40.6s\tremaining: 4.51s\n",
            "45:\tlearn: 0.2292871\ttotal: 41.4s\tremaining: 3.6s\n",
            "46:\tlearn: 0.2284113\ttotal: 42.3s\tremaining: 2.7s\n",
            "47:\tlearn: 0.2275762\ttotal: 43.2s\tremaining: 1.8s\n",
            "48:\tlearn: 0.2267659\ttotal: 44.1s\tremaining: 900ms\n",
            "49:\tlearn: 0.2260889\ttotal: 44.9s\tremaining: 0us\n",
            "0:\tlearn: 0.6822795\ttotal: 1.99s\tremaining: 17.9s\n",
            "1:\tlearn: 0.6721317\ttotal: 4.1s\tremaining: 16.4s\n",
            "2:\tlearn: 0.6620484\ttotal: 6.14s\tremaining: 14.3s\n",
            "3:\tlearn: 0.6518575\ttotal: 8.15s\tremaining: 12.2s\n",
            "4:\tlearn: 0.6420156\ttotal: 10.2s\tremaining: 10.2s\n",
            "5:\tlearn: 0.6320416\ttotal: 12.2s\tremaining: 8.16s\n",
            "6:\tlearn: 0.6228722\ttotal: 14.3s\tremaining: 6.14s\n",
            "7:\tlearn: 0.6138611\ttotal: 16.4s\tremaining: 4.09s\n",
            "8:\tlearn: 0.6050831\ttotal: 18.3s\tremaining: 2.04s\n",
            "9:\tlearn: 0.5964271\ttotal: 20.4s\tremaining: 0us\n",
            "0:\tlearn: 0.6824544\ttotal: 2.06s\tremaining: 18.6s\n",
            "1:\tlearn: 0.6717300\ttotal: 4.17s\tremaining: 16.7s\n",
            "2:\tlearn: 0.6613662\ttotal: 6.22s\tremaining: 14.5s\n",
            "3:\tlearn: 0.6512759\ttotal: 8.3s\tremaining: 12.5s\n",
            "4:\tlearn: 0.6412425\ttotal: 10.4s\tremaining: 10.4s\n",
            "5:\tlearn: 0.6318688\ttotal: 12.4s\tremaining: 8.3s\n",
            "6:\tlearn: 0.6228676\ttotal: 14.4s\tremaining: 6.19s\n",
            "7:\tlearn: 0.6140105\ttotal: 16.5s\tremaining: 4.11s\n",
            "8:\tlearn: 0.6054270\ttotal: 18.6s\tremaining: 2.06s\n",
            "9:\tlearn: 0.5966067\ttotal: 20.6s\tremaining: 0us\n",
            "0:\tlearn: 0.6824990\ttotal: 2.02s\tremaining: 18.2s\n",
            "1:\tlearn: 0.6717729\ttotal: 4.2s\tremaining: 16.8s\n",
            "2:\tlearn: 0.6613022\ttotal: 6.23s\tremaining: 14.5s\n",
            "3:\tlearn: 0.6511008\ttotal: 8.28s\tremaining: 12.4s\n",
            "4:\tlearn: 0.6414309\ttotal: 10.3s\tremaining: 10.3s\n",
            "5:\tlearn: 0.6316761\ttotal: 12.4s\tremaining: 8.26s\n",
            "6:\tlearn: 0.6222269\ttotal: 14.4s\tremaining: 6.19s\n",
            "7:\tlearn: 0.6135794\ttotal: 16.5s\tremaining: 4.11s\n",
            "8:\tlearn: 0.6047252\ttotal: 18.5s\tremaining: 2.06s\n",
            "9:\tlearn: 0.5960678\ttotal: 20.6s\tremaining: 0us\n",
            "0:\tlearn: 0.6412657\ttotal: 1.96s\tremaining: 17.6s\n",
            "1:\tlearn: 0.5960728\ttotal: 3.93s\tremaining: 15.7s\n",
            "2:\tlearn: 0.5561942\ttotal: 5.88s\tremaining: 13.7s\n",
            "3:\tlearn: 0.5196182\ttotal: 8.04s\tremaining: 12.1s\n",
            "4:\tlearn: 0.4882482\ttotal: 10.1s\tremaining: 10.1s\n",
            "5:\tlearn: 0.4582397\ttotal: 12.2s\tremaining: 8.1s\n",
            "6:\tlearn: 0.4322941\ttotal: 14.2s\tremaining: 6.1s\n",
            "7:\tlearn: 0.4101532\ttotal: 16.3s\tremaining: 4.07s\n",
            "8:\tlearn: 0.3906634\ttotal: 18.4s\tremaining: 2.04s\n",
            "9:\tlearn: 0.3732546\ttotal: 20.4s\tremaining: 0us\n",
            "0:\tlearn: 0.6416465\ttotal: 2.11s\tremaining: 19s\n",
            "1:\tlearn: 0.5948059\ttotal: 4.24s\tremaining: 16.9s\n",
            "2:\tlearn: 0.5525334\ttotal: 6.28s\tremaining: 14.6s\n",
            "3:\tlearn: 0.5175643\ttotal: 8.35s\tremaining: 12.5s\n",
            "4:\tlearn: 0.4849942\ttotal: 10.5s\tremaining: 10.5s\n",
            "5:\tlearn: 0.4568819\ttotal: 12.6s\tremaining: 8.41s\n",
            "6:\tlearn: 0.4334214\ttotal: 14.7s\tremaining: 6.29s\n",
            "7:\tlearn: 0.4111937\ttotal: 16.7s\tremaining: 4.17s\n",
            "8:\tlearn: 0.3923286\ttotal: 18.7s\tremaining: 2.08s\n",
            "9:\tlearn: 0.3747646\ttotal: 20.7s\tremaining: 0us\n",
            "0:\tlearn: 0.6412086\ttotal: 1.97s\tremaining: 17.7s\n",
            "1:\tlearn: 0.5945999\ttotal: 4.08s\tremaining: 16.3s\n",
            "2:\tlearn: 0.5522916\ttotal: 6.23s\tremaining: 14.5s\n",
            "3:\tlearn: 0.5167791\ttotal: 8.4s\tremaining: 12.6s\n",
            "4:\tlearn: 0.4855508\ttotal: 10.6s\tremaining: 10.6s\n",
            "5:\tlearn: 0.4577384\ttotal: 12.6s\tremaining: 8.38s\n",
            "6:\tlearn: 0.4316233\ttotal: 14.6s\tremaining: 6.26s\n",
            "7:\tlearn: 0.4100293\ttotal: 16.8s\tremaining: 4.21s\n",
            "8:\tlearn: 0.3907986\ttotal: 18.9s\tremaining: 2.1s\n",
            "9:\tlearn: 0.3730390\ttotal: 21s\tremaining: 0us\n",
            "0:\tlearn: 0.6822795\ttotal: 2.08s\tremaining: 1m 42s\n",
            "1:\tlearn: 0.6721317\ttotal: 4.06s\tremaining: 1m 37s\n",
            "2:\tlearn: 0.6620484\ttotal: 6.04s\tremaining: 1m 34s\n",
            "3:\tlearn: 0.6518575\ttotal: 8.08s\tremaining: 1m 32s\n",
            "4:\tlearn: 0.6420156\ttotal: 10.1s\tremaining: 1m 31s\n",
            "5:\tlearn: 0.6320416\ttotal: 12.2s\tremaining: 1m 29s\n",
            "6:\tlearn: 0.6228722\ttotal: 14.2s\tremaining: 1m 26s\n",
            "7:\tlearn: 0.6138611\ttotal: 16.1s\tremaining: 1m 24s\n",
            "8:\tlearn: 0.6050831\ttotal: 18.1s\tremaining: 1m 22s\n",
            "9:\tlearn: 0.5964271\ttotal: 20.1s\tremaining: 1m 20s\n",
            "10:\tlearn: 0.5877319\ttotal: 22.2s\tremaining: 1m 18s\n",
            "11:\tlearn: 0.5794068\ttotal: 24.2s\tremaining: 1m 16s\n",
            "12:\tlearn: 0.5714630\ttotal: 26.2s\tremaining: 1m 14s\n",
            "13:\tlearn: 0.5636303\ttotal: 28.3s\tremaining: 1m 12s\n",
            "14:\tlearn: 0.5558742\ttotal: 30.5s\tremaining: 1m 11s\n",
            "15:\tlearn: 0.5483189\ttotal: 32.5s\tremaining: 1m 9s\n",
            "16:\tlearn: 0.5413271\ttotal: 34.5s\tremaining: 1m 6s\n",
            "17:\tlearn: 0.5344514\ttotal: 36.5s\tremaining: 1m 4s\n",
            "18:\tlearn: 0.5274733\ttotal: 38.6s\tremaining: 1m 3s\n",
            "19:\tlearn: 0.5206425\ttotal: 40.8s\tremaining: 1m 1s\n",
            "20:\tlearn: 0.5137931\ttotal: 42.9s\tremaining: 59.2s\n",
            "21:\tlearn: 0.5072877\ttotal: 44.9s\tremaining: 57.2s\n",
            "22:\tlearn: 0.5010876\ttotal: 47s\tremaining: 55.2s\n",
            "23:\tlearn: 0.4949846\ttotal: 49.1s\tremaining: 53.2s\n",
            "24:\tlearn: 0.4888715\ttotal: 51.3s\tremaining: 51.3s\n",
            "25:\tlearn: 0.4828126\ttotal: 53.4s\tremaining: 49.3s\n",
            "26:\tlearn: 0.4771817\ttotal: 55.4s\tremaining: 47.2s\n",
            "27:\tlearn: 0.4716342\ttotal: 57.4s\tremaining: 45.1s\n",
            "28:\tlearn: 0.4661051\ttotal: 59.5s\tremaining: 43.1s\n",
            "29:\tlearn: 0.4606811\ttotal: 1m 1s\tremaining: 41.1s\n",
            "30:\tlearn: 0.4554964\ttotal: 1m 3s\tremaining: 39.1s\n",
            "31:\tlearn: 0.4503054\ttotal: 1m 5s\tremaining: 37s\n",
            "32:\tlearn: 0.4451069\ttotal: 1m 7s\tremaining: 34.9s\n",
            "33:\tlearn: 0.4400225\ttotal: 1m 9s\tremaining: 32.9s\n",
            "34:\tlearn: 0.4354190\ttotal: 1m 11s\tremaining: 30.8s\n",
            "35:\tlearn: 0.4306716\ttotal: 1m 13s\tremaining: 28.8s\n",
            "36:\tlearn: 0.4262924\ttotal: 1m 16s\tremaining: 26.7s\n",
            "37:\tlearn: 0.4218514\ttotal: 1m 18s\tremaining: 24.7s\n",
            "38:\tlearn: 0.4176246\ttotal: 1m 20s\tremaining: 22.6s\n",
            "39:\tlearn: 0.4133867\ttotal: 1m 22s\tremaining: 20.5s\n",
            "40:\tlearn: 0.4094360\ttotal: 1m 24s\tremaining: 18.5s\n",
            "41:\tlearn: 0.4053101\ttotal: 1m 26s\tremaining: 16.4s\n",
            "42:\tlearn: 0.4013823\ttotal: 1m 28s\tremaining: 14.4s\n",
            "43:\tlearn: 0.3975389\ttotal: 1m 30s\tremaining: 12.3s\n",
            "44:\tlearn: 0.3937406\ttotal: 1m 32s\tremaining: 10.3s\n",
            "45:\tlearn: 0.3899454\ttotal: 1m 34s\tremaining: 8.22s\n",
            "46:\tlearn: 0.3864479\ttotal: 1m 36s\tremaining: 6.17s\n",
            "47:\tlearn: 0.3830430\ttotal: 1m 38s\tremaining: 4.11s\n",
            "48:\tlearn: 0.3795209\ttotal: 1m 40s\tremaining: 2.06s\n",
            "49:\tlearn: 0.3761652\ttotal: 1m 42s\tremaining: 0us\n",
            "0:\tlearn: 0.6824544\ttotal: 1.93s\tremaining: 1m 34s\n",
            "1:\tlearn: 0.6717300\ttotal: 3.96s\tremaining: 1m 34s\n",
            "2:\tlearn: 0.6613662\ttotal: 5.91s\tremaining: 1m 32s\n",
            "3:\tlearn: 0.6512759\ttotal: 7.85s\tremaining: 1m 30s\n",
            "4:\tlearn: 0.6412425\ttotal: 9.88s\tremaining: 1m 28s\n",
            "5:\tlearn: 0.6318688\ttotal: 11.9s\tremaining: 1m 27s\n",
            "6:\tlearn: 0.6228676\ttotal: 14.1s\tremaining: 1m 26s\n",
            "7:\tlearn: 0.6140105\ttotal: 16s\tremaining: 1m 23s\n",
            "8:\tlearn: 0.6054270\ttotal: 18s\tremaining: 1m 21s\n",
            "9:\tlearn: 0.5966067\ttotal: 19.9s\tremaining: 1m 19s\n",
            "10:\tlearn: 0.5882623\ttotal: 22s\tremaining: 1m 17s\n",
            "11:\tlearn: 0.5800234\ttotal: 24.1s\tremaining: 1m 16s\n",
            "12:\tlearn: 0.5720310\ttotal: 26.1s\tremaining: 1m 14s\n",
            "13:\tlearn: 0.5642809\ttotal: 28s\tremaining: 1m 12s\n",
            "14:\tlearn: 0.5567773\ttotal: 30s\tremaining: 1m 10s\n",
            "15:\tlearn: 0.5493415\ttotal: 32.1s\tremaining: 1m 8s\n",
            "16:\tlearn: 0.5418562\ttotal: 34.2s\tremaining: 1m 6s\n",
            "17:\tlearn: 0.5346870\ttotal: 36.2s\tremaining: 1m 4s\n",
            "18:\tlearn: 0.5276315\ttotal: 38.2s\tremaining: 1m 2s\n",
            "19:\tlearn: 0.5209182\ttotal: 40.2s\tremaining: 1m\n",
            "20:\tlearn: 0.5144205\ttotal: 42.3s\tremaining: 58.4s\n",
            "21:\tlearn: 0.5080027\ttotal: 44.4s\tremaining: 56.5s\n",
            "22:\tlearn: 0.5017413\ttotal: 46.5s\tremaining: 54.5s\n",
            "23:\tlearn: 0.4961022\ttotal: 48.4s\tremaining: 52.4s\n",
            "24:\tlearn: 0.4898407\ttotal: 50.4s\tremaining: 50.4s\n",
            "25:\tlearn: 0.4841530\ttotal: 52.4s\tremaining: 48.3s\n",
            "26:\tlearn: 0.4783095\ttotal: 54.5s\tremaining: 46.4s\n",
            "27:\tlearn: 0.4726863\ttotal: 56.5s\tremaining: 44.4s\n",
            "28:\tlearn: 0.4673588\ttotal: 58.7s\tremaining: 42.5s\n",
            "29:\tlearn: 0.4620599\ttotal: 1m\tremaining: 40.5s\n",
            "30:\tlearn: 0.4568585\ttotal: 1m 2s\tremaining: 38.5s\n",
            "31:\tlearn: 0.4517385\ttotal: 1m 5s\tremaining: 36.6s\n",
            "32:\tlearn: 0.4466916\ttotal: 1m 7s\tremaining: 34.7s\n",
            "33:\tlearn: 0.4416490\ttotal: 1m 9s\tremaining: 32.6s\n",
            "34:\tlearn: 0.4369025\ttotal: 1m 11s\tremaining: 30.6s\n",
            "35:\tlearn: 0.4321393\ttotal: 1m 13s\tremaining: 28.6s\n",
            "36:\tlearn: 0.4275938\ttotal: 1m 15s\tremaining: 26.7s\n",
            "37:\tlearn: 0.4231880\ttotal: 1m 18s\tremaining: 24.6s\n",
            "38:\tlearn: 0.4188581\ttotal: 1m 20s\tremaining: 22.6s\n",
            "39:\tlearn: 0.4146151\ttotal: 1m 22s\tremaining: 20.6s\n",
            "40:\tlearn: 0.4104316\ttotal: 1m 24s\tremaining: 18.5s\n",
            "41:\tlearn: 0.4062635\ttotal: 1m 26s\tremaining: 16.5s\n",
            "42:\tlearn: 0.4022827\ttotal: 1m 28s\tremaining: 14.4s\n",
            "43:\tlearn: 0.3984729\ttotal: 1m 30s\tremaining: 12.3s\n",
            "44:\tlearn: 0.3946940\ttotal: 1m 32s\tremaining: 10.3s\n",
            "45:\tlearn: 0.3910221\ttotal: 1m 34s\tremaining: 8.24s\n",
            "46:\tlearn: 0.3874882\ttotal: 1m 36s\tremaining: 6.18s\n",
            "47:\tlearn: 0.3840209\ttotal: 1m 38s\tremaining: 4.12s\n",
            "48:\tlearn: 0.3807800\ttotal: 1m 40s\tremaining: 2.06s\n",
            "49:\tlearn: 0.3776655\ttotal: 1m 42s\tremaining: 0us\n",
            "0:\tlearn: 0.6824990\ttotal: 1.94s\tremaining: 1m 35s\n",
            "1:\tlearn: 0.6717729\ttotal: 3.96s\tremaining: 1m 35s\n",
            "2:\tlearn: 0.6613022\ttotal: 5.97s\tremaining: 1m 33s\n",
            "3:\tlearn: 0.6511008\ttotal: 8.16s\tremaining: 1m 33s\n",
            "4:\tlearn: 0.6414309\ttotal: 10.3s\tremaining: 1m 32s\n",
            "5:\tlearn: 0.6316761\ttotal: 12.3s\tremaining: 1m 29s\n",
            "6:\tlearn: 0.6222269\ttotal: 14.3s\tremaining: 1m 27s\n",
            "7:\tlearn: 0.6135794\ttotal: 16.4s\tremaining: 1m 25s\n",
            "8:\tlearn: 0.6047252\ttotal: 18.5s\tremaining: 1m 24s\n",
            "9:\tlearn: 0.5960678\ttotal: 20.4s\tremaining: 1m 21s\n",
            "10:\tlearn: 0.5875452\ttotal: 22.4s\tremaining: 1m 19s\n",
            "11:\tlearn: 0.5789958\ttotal: 24.4s\tremaining: 1m 17s\n",
            "12:\tlearn: 0.5709600\ttotal: 26.5s\tremaining: 1m 15s\n",
            "13:\tlearn: 0.5627714\ttotal: 28.6s\tremaining: 1m 13s\n",
            "14:\tlearn: 0.5549248\ttotal: 30.7s\tremaining: 1m 11s\n",
            "15:\tlearn: 0.5477036\ttotal: 32.7s\tremaining: 1m 9s\n",
            "16:\tlearn: 0.5404039\ttotal: 34.7s\tremaining: 1m 7s\n",
            "17:\tlearn: 0.5332797\ttotal: 36.8s\tremaining: 1m 5s\n",
            "18:\tlearn: 0.5262596\ttotal: 39s\tremaining: 1m 3s\n",
            "19:\tlearn: 0.5194738\ttotal: 41.1s\tremaining: 1m 1s\n",
            "20:\tlearn: 0.5127365\ttotal: 43.1s\tremaining: 59.5s\n",
            "21:\tlearn: 0.5063602\ttotal: 45.1s\tremaining: 57.4s\n",
            "22:\tlearn: 0.4999721\ttotal: 47.3s\tremaining: 55.5s\n",
            "23:\tlearn: 0.4941724\ttotal: 49.6s\tremaining: 53.7s\n",
            "24:\tlearn: 0.4882492\ttotal: 51.6s\tremaining: 51.6s\n",
            "25:\tlearn: 0.4823354\ttotal: 53.7s\tremaining: 49.5s\n",
            "26:\tlearn: 0.4764591\ttotal: 55.7s\tremaining: 47.5s\n",
            "27:\tlearn: 0.4708719\ttotal: 57.9s\tremaining: 45.5s\n",
            "28:\tlearn: 0.4652455\ttotal: 1m\tremaining: 43.5s\n",
            "29:\tlearn: 0.4600215\ttotal: 1m 2s\tremaining: 41.5s\n",
            "30:\tlearn: 0.4547494\ttotal: 1m 4s\tremaining: 39.5s\n",
            "31:\tlearn: 0.4496882\ttotal: 1m 6s\tremaining: 37.5s\n",
            "32:\tlearn: 0.4445393\ttotal: 1m 8s\tremaining: 35.4s\n",
            "33:\tlearn: 0.4396453\ttotal: 1m 10s\tremaining: 33.4s\n",
            "34:\tlearn: 0.4348131\ttotal: 1m 13s\tremaining: 31.4s\n",
            "35:\tlearn: 0.4302854\ttotal: 1m 15s\tremaining: 29.3s\n",
            "36:\tlearn: 0.4259310\ttotal: 1m 17s\tremaining: 27.2s\n",
            "37:\tlearn: 0.4214068\ttotal: 1m 19s\tremaining: 25.1s\n",
            "38:\tlearn: 0.4171222\ttotal: 1m 21s\tremaining: 23s\n",
            "39:\tlearn: 0.4128300\ttotal: 1m 23s\tremaining: 20.9s\n",
            "40:\tlearn: 0.4086350\ttotal: 1m 25s\tremaining: 18.9s\n",
            "41:\tlearn: 0.4047904\ttotal: 1m 28s\tremaining: 16.8s\n",
            "42:\tlearn: 0.4007511\ttotal: 1m 30s\tremaining: 14.7s\n",
            "43:\tlearn: 0.3967784\ttotal: 1m 32s\tremaining: 12.6s\n",
            "44:\tlearn: 0.3932727\ttotal: 1m 34s\tremaining: 10.5s\n",
            "45:\tlearn: 0.3895713\ttotal: 1m 36s\tremaining: 8.41s\n",
            "46:\tlearn: 0.3861099\ttotal: 1m 38s\tremaining: 6.32s\n",
            "47:\tlearn: 0.3828681\ttotal: 1m 41s\tremaining: 4.21s\n",
            "48:\tlearn: 0.3794274\ttotal: 1m 43s\tremaining: 2.1s\n",
            "49:\tlearn: 0.3760152\ttotal: 1m 45s\tremaining: 0us\n",
            "0:\tlearn: 0.6412657\ttotal: 2s\tremaining: 1m 38s\n",
            "1:\tlearn: 0.5960728\ttotal: 4.01s\tremaining: 1m 36s\n",
            "2:\tlearn: 0.5561942\ttotal: 6.07s\tremaining: 1m 35s\n",
            "3:\tlearn: 0.5196182\ttotal: 8.22s\tremaining: 1m 34s\n",
            "4:\tlearn: 0.4882482\ttotal: 10.3s\tremaining: 1m 32s\n",
            "5:\tlearn: 0.4582397\ttotal: 12.3s\tremaining: 1m 30s\n",
            "6:\tlearn: 0.4322941\ttotal: 14.4s\tremaining: 1m 28s\n",
            "7:\tlearn: 0.4101532\ttotal: 16.5s\tremaining: 1m 26s\n",
            "8:\tlearn: 0.3906634\ttotal: 18.7s\tremaining: 1m 25s\n",
            "9:\tlearn: 0.3732546\ttotal: 20.8s\tremaining: 1m 23s\n",
            "10:\tlearn: 0.3576878\ttotal: 22.9s\tremaining: 1m 21s\n",
            "11:\tlearn: 0.3435235\ttotal: 25s\tremaining: 1m 19s\n",
            "12:\tlearn: 0.3314966\ttotal: 27.2s\tremaining: 1m 17s\n",
            "13:\tlearn: 0.3205575\ttotal: 29.4s\tremaining: 1m 15s\n",
            "14:\tlearn: 0.3110957\ttotal: 31.4s\tremaining: 1m 13s\n",
            "15:\tlearn: 0.3025980\ttotal: 33.5s\tremaining: 1m 11s\n",
            "16:\tlearn: 0.2948785\ttotal: 35.6s\tremaining: 1m 9s\n",
            "17:\tlearn: 0.2877405\ttotal: 37.7s\tremaining: 1m 7s\n",
            "18:\tlearn: 0.2811527\ttotal: 39.8s\tremaining: 1m 4s\n",
            "19:\tlearn: 0.2753835\ttotal: 41.9s\tremaining: 1m 2s\n",
            "20:\tlearn: 0.2703108\ttotal: 44s\tremaining: 1m\n",
            "21:\tlearn: 0.2656107\ttotal: 46.1s\tremaining: 58.7s\n",
            "22:\tlearn: 0.2615185\ttotal: 48.2s\tremaining: 56.6s\n",
            "23:\tlearn: 0.2570912\ttotal: 50.3s\tremaining: 54.5s\n",
            "24:\tlearn: 0.2530612\ttotal: 52.4s\tremaining: 52.4s\n",
            "25:\tlearn: 0.2497600\ttotal: 54.4s\tremaining: 50.2s\n",
            "26:\tlearn: 0.2469565\ttotal: 56.5s\tremaining: 48.1s\n",
            "27:\tlearn: 0.2441222\ttotal: 58.7s\tremaining: 46.1s\n",
            "28:\tlearn: 0.2415760\ttotal: 1m\tremaining: 44s\n",
            "29:\tlearn: 0.2392626\ttotal: 1m 2s\tremaining: 41.8s\n",
            "30:\tlearn: 0.2371815\ttotal: 1m 4s\tremaining: 39.7s\n",
            "31:\tlearn: 0.2351495\ttotal: 1m 6s\tremaining: 37.6s\n",
            "32:\tlearn: 0.2332840\ttotal: 1m 9s\tremaining: 35.6s\n",
            "33:\tlearn: 0.2315441\ttotal: 1m 11s\tremaining: 33.5s\n",
            "34:\tlearn: 0.2296604\ttotal: 1m 13s\tremaining: 31.4s\n",
            "35:\tlearn: 0.2280904\ttotal: 1m 15s\tremaining: 29.4s\n",
            "36:\tlearn: 0.2266402\ttotal: 1m 17s\tremaining: 27.3s\n",
            "37:\tlearn: 0.2252782\ttotal: 1m 19s\tremaining: 25.2s\n",
            "38:\tlearn: 0.2238669\ttotal: 1m 22s\tremaining: 23.1s\n",
            "39:\tlearn: 0.2220975\ttotal: 1m 24s\tremaining: 21s\n",
            "40:\tlearn: 0.2210793\ttotal: 1m 26s\tremaining: 18.9s\n",
            "41:\tlearn: 0.2196775\ttotal: 1m 28s\tremaining: 16.8s\n",
            "42:\tlearn: 0.2185452\ttotal: 1m 30s\tremaining: 14.7s\n",
            "43:\tlearn: 0.2174523\ttotal: 1m 32s\tremaining: 12.6s\n",
            "44:\tlearn: 0.2165240\ttotal: 1m 34s\tremaining: 10.5s\n",
            "45:\tlearn: 0.2156332\ttotal: 1m 36s\tremaining: 8.4s\n",
            "46:\tlearn: 0.2148763\ttotal: 1m 38s\tremaining: 6.3s\n",
            "47:\tlearn: 0.2137415\ttotal: 1m 40s\tremaining: 4.2s\n",
            "48:\tlearn: 0.2129006\ttotal: 1m 42s\tremaining: 2.1s\n",
            "49:\tlearn: 0.2120866\ttotal: 1m 44s\tremaining: 0us\n",
            "0:\tlearn: 0.6416465\ttotal: 1.93s\tremaining: 1m 34s\n",
            "1:\tlearn: 0.5948059\ttotal: 3.91s\tremaining: 1m 33s\n",
            "2:\tlearn: 0.5525334\ttotal: 5.93s\tremaining: 1m 32s\n",
            "3:\tlearn: 0.5175643\ttotal: 8.05s\tremaining: 1m 32s\n",
            "4:\tlearn: 0.4849942\ttotal: 10.2s\tremaining: 1m 31s\n",
            "5:\tlearn: 0.4568819\ttotal: 12.2s\tremaining: 1m 29s\n",
            "6:\tlearn: 0.4334214\ttotal: 14.2s\tremaining: 1m 27s\n",
            "7:\tlearn: 0.4111937\ttotal: 16.2s\tremaining: 1m 24s\n",
            "8:\tlearn: 0.3923286\ttotal: 18.3s\tremaining: 1m 23s\n",
            "9:\tlearn: 0.3747646\ttotal: 20.4s\tremaining: 1m 21s\n",
            "10:\tlearn: 0.3587953\ttotal: 22.6s\tremaining: 1m 19s\n",
            "11:\tlearn: 0.3453070\ttotal: 24.7s\tremaining: 1m 18s\n",
            "12:\tlearn: 0.3334649\ttotal: 26.8s\tremaining: 1m 16s\n",
            "13:\tlearn: 0.3224383\ttotal: 28.9s\tremaining: 1m 14s\n",
            "14:\tlearn: 0.3128099\ttotal: 31s\tremaining: 1m 12s\n",
            "15:\tlearn: 0.3040967\ttotal: 33s\tremaining: 1m 10s\n",
            "16:\tlearn: 0.2961638\ttotal: 35.1s\tremaining: 1m 8s\n",
            "17:\tlearn: 0.2891274\ttotal: 37.1s\tremaining: 1m 6s\n",
            "18:\tlearn: 0.2828349\ttotal: 39.3s\tremaining: 1m 4s\n",
            "19:\tlearn: 0.2768728\ttotal: 41.4s\tremaining: 1m 2s\n",
            "20:\tlearn: 0.2713938\ttotal: 43.4s\tremaining: 60s\n",
            "21:\tlearn: 0.2667998\ttotal: 45.5s\tremaining: 57.9s\n",
            "22:\tlearn: 0.2625710\ttotal: 47.6s\tremaining: 55.9s\n",
            "23:\tlearn: 0.2588444\ttotal: 49.8s\tremaining: 54s\n",
            "24:\tlearn: 0.2553219\ttotal: 51.9s\tremaining: 51.9s\n",
            "25:\tlearn: 0.2520261\ttotal: 54s\tremaining: 49.8s\n",
            "26:\tlearn: 0.2491411\ttotal: 56.1s\tremaining: 47.8s\n",
            "27:\tlearn: 0.2458238\ttotal: 58.2s\tremaining: 45.7s\n",
            "28:\tlearn: 0.2432428\ttotal: 1m\tremaining: 43.7s\n",
            "29:\tlearn: 0.2409113\ttotal: 1m 2s\tremaining: 41.6s\n",
            "30:\tlearn: 0.2382884\ttotal: 1m 4s\tremaining: 39.6s\n",
            "31:\tlearn: 0.2363836\ttotal: 1m 6s\tremaining: 37.6s\n",
            "32:\tlearn: 0.2344735\ttotal: 1m 8s\tremaining: 35.5s\n",
            "33:\tlearn: 0.2327262\ttotal: 1m 11s\tremaining: 33.5s\n",
            "34:\tlearn: 0.2312105\ttotal: 1m 13s\tremaining: 31.4s\n",
            "35:\tlearn: 0.2297504\ttotal: 1m 15s\tremaining: 29.3s\n",
            "36:\tlearn: 0.2283043\ttotal: 1m 17s\tremaining: 27.2s\n",
            "37:\tlearn: 0.2270290\ttotal: 1m 19s\tremaining: 25.2s\n",
            "38:\tlearn: 0.2255326\ttotal: 1m 21s\tremaining: 23.1s\n",
            "39:\tlearn: 0.2244746\ttotal: 1m 23s\tremaining: 21s\n",
            "40:\tlearn: 0.2231063\ttotal: 1m 25s\tremaining: 18.9s\n",
            "41:\tlearn: 0.2219619\ttotal: 1m 28s\tremaining: 16.8s\n",
            "42:\tlearn: 0.2209029\ttotal: 1m 30s\tremaining: 14.8s\n",
            "43:\tlearn: 0.2200181\ttotal: 1m 32s\tremaining: 12.7s\n",
            "44:\tlearn: 0.2191680\ttotal: 1m 35s\tremaining: 10.6s\n",
            "45:\tlearn: 0.2180965\ttotal: 1m 37s\tremaining: 8.45s\n",
            "46:\tlearn: 0.2171934\ttotal: 1m 39s\tremaining: 6.34s\n",
            "47:\tlearn: 0.2164390\ttotal: 1m 41s\tremaining: 4.23s\n",
            "48:\tlearn: 0.2157098\ttotal: 1m 43s\tremaining: 2.11s\n",
            "49:\tlearn: 0.2144773\ttotal: 1m 45s\tremaining: 0us\n",
            "0:\tlearn: 0.6412086\ttotal: 2.13s\tremaining: 1m 44s\n",
            "1:\tlearn: 0.5945999\ttotal: 4.28s\tremaining: 1m 42s\n",
            "2:\tlearn: 0.5522916\ttotal: 6.49s\tremaining: 1m 41s\n",
            "3:\tlearn: 0.5167791\ttotal: 8.7s\tremaining: 1m 40s\n",
            "4:\tlearn: 0.4855508\ttotal: 10.9s\tremaining: 1m 37s\n",
            "5:\tlearn: 0.4577384\ttotal: 13s\tremaining: 1m 35s\n",
            "6:\tlearn: 0.4316233\ttotal: 15.1s\tremaining: 1m 32s\n",
            "7:\tlearn: 0.4100293\ttotal: 17.4s\tremaining: 1m 31s\n",
            "8:\tlearn: 0.3907986\ttotal: 19.6s\tremaining: 1m 29s\n",
            "9:\tlearn: 0.3730390\ttotal: 21.9s\tremaining: 1m 27s\n",
            "10:\tlearn: 0.3571605\ttotal: 24s\tremaining: 1m 25s\n",
            "11:\tlearn: 0.3434473\ttotal: 26.2s\tremaining: 1m 22s\n",
            "12:\tlearn: 0.3311046\ttotal: 28.4s\tremaining: 1m 20s\n",
            "13:\tlearn: 0.3205518\ttotal: 30.5s\tremaining: 1m 18s\n",
            "14:\tlearn: 0.3099238\ttotal: 32.7s\tremaining: 1m 16s\n",
            "15:\tlearn: 0.3016092\ttotal: 34.8s\tremaining: 1m 13s\n",
            "16:\tlearn: 0.2938547\ttotal: 37s\tremaining: 1m 11s\n",
            "17:\tlearn: 0.2872329\ttotal: 39.1s\tremaining: 1m 9s\n",
            "18:\tlearn: 0.2812461\ttotal: 41.2s\tremaining: 1m 7s\n",
            "19:\tlearn: 0.2754187\ttotal: 43.3s\tremaining: 1m 4s\n",
            "20:\tlearn: 0.2701999\ttotal: 45.5s\tremaining: 1m 2s\n",
            "21:\tlearn: 0.2655464\ttotal: 47.7s\tremaining: 1m\n",
            "22:\tlearn: 0.2612188\ttotal: 49.8s\tremaining: 58.4s\n",
            "23:\tlearn: 0.2576311\ttotal: 51.8s\tremaining: 56.2s\n",
            "24:\tlearn: 0.2541683\ttotal: 54s\tremaining: 54s\n",
            "25:\tlearn: 0.2505628\ttotal: 56.1s\tremaining: 51.8s\n",
            "26:\tlearn: 0.2474610\ttotal: 58.3s\tremaining: 49.7s\n",
            "27:\tlearn: 0.2447274\ttotal: 1m\tremaining: 47.4s\n",
            "28:\tlearn: 0.2423467\ttotal: 1m 2s\tremaining: 45.2s\n",
            "29:\tlearn: 0.2396981\ttotal: 1m 4s\tremaining: 43s\n",
            "30:\tlearn: 0.2376515\ttotal: 1m 6s\tremaining: 40.9s\n",
            "31:\tlearn: 0.2357063\ttotal: 1m 8s\tremaining: 38.7s\n",
            "32:\tlearn: 0.2337854\ttotal: 1m 10s\tremaining: 36.5s\n",
            "33:\tlearn: 0.2321758\ttotal: 1m 12s\tremaining: 34.3s\n",
            "34:\tlearn: 0.2305499\ttotal: 1m 14s\tremaining: 32.1s\n",
            "35:\tlearn: 0.2286473\ttotal: 1m 17s\tremaining: 30s\n",
            "36:\tlearn: 0.2273094\ttotal: 1m 19s\tremaining: 27.8s\n",
            "37:\tlearn: 0.2259166\ttotal: 1m 21s\tremaining: 25.7s\n",
            "38:\tlearn: 0.2245336\ttotal: 1m 23s\tremaining: 23.5s\n",
            "39:\tlearn: 0.2233593\ttotal: 1m 25s\tremaining: 21.4s\n",
            "40:\tlearn: 0.2221995\ttotal: 1m 27s\tremaining: 19.2s\n",
            "41:\tlearn: 0.2211216\ttotal: 1m 29s\tremaining: 17.1s\n",
            "42:\tlearn: 0.2201522\ttotal: 1m 31s\tremaining: 14.9s\n",
            "43:\tlearn: 0.2192061\ttotal: 1m 33s\tremaining: 12.8s\n",
            "44:\tlearn: 0.2178582\ttotal: 1m 35s\tremaining: 10.7s\n",
            "45:\tlearn: 0.2168594\ttotal: 1m 38s\tremaining: 8.53s\n",
            "46:\tlearn: 0.2159274\ttotal: 1m 40s\tremaining: 6.4s\n",
            "47:\tlearn: 0.2151207\ttotal: 1m 42s\tremaining: 4.26s\n",
            "48:\tlearn: 0.2143113\ttotal: 1m 44s\tremaining: 2.13s\n",
            "49:\tlearn: 0.2132510\ttotal: 1m 46s\tremaining: 0us\n",
            "0:\tlearn: 0.6429268\ttotal: 2.6s\tremaining: 2m 7s\n",
            "1:\tlearn: 0.5951004\ttotal: 4.78s\tremaining: 1m 54s\n",
            "2:\tlearn: 0.5538846\ttotal: 7.06s\tremaining: 1m 50s\n",
            "3:\tlearn: 0.5163837\ttotal: 9.33s\tremaining: 1m 47s\n",
            "4:\tlearn: 0.4837383\ttotal: 11.6s\tremaining: 1m 44s\n",
            "5:\tlearn: 0.4556190\ttotal: 13.7s\tremaining: 1m 40s\n",
            "6:\tlearn: 0.4307594\ttotal: 16s\tremaining: 1m 38s\n",
            "7:\tlearn: 0.4068405\ttotal: 18.3s\tremaining: 1m 36s\n",
            "8:\tlearn: 0.3869084\ttotal: 20.5s\tremaining: 1m 33s\n",
            "9:\tlearn: 0.3695554\ttotal: 22.8s\tremaining: 1m 31s\n",
            "10:\tlearn: 0.3546398\ttotal: 25s\tremaining: 1m 28s\n",
            "11:\tlearn: 0.3410811\ttotal: 27.2s\tremaining: 1m 26s\n",
            "12:\tlearn: 0.3293443\ttotal: 29.3s\tremaining: 1m 23s\n",
            "13:\tlearn: 0.3182169\ttotal: 31.5s\tremaining: 1m 20s\n",
            "14:\tlearn: 0.3083950\ttotal: 33.6s\tremaining: 1m 18s\n",
            "15:\tlearn: 0.3000947\ttotal: 35.9s\tremaining: 1m 16s\n",
            "16:\tlearn: 0.2927162\ttotal: 38s\tremaining: 1m 13s\n",
            "17:\tlearn: 0.2856499\ttotal: 40.2s\tremaining: 1m 11s\n",
            "18:\tlearn: 0.2795905\ttotal: 42.3s\tremaining: 1m 8s\n",
            "19:\tlearn: 0.2740656\ttotal: 44.5s\tremaining: 1m 6s\n",
            "20:\tlearn: 0.2688452\ttotal: 46.7s\tremaining: 1m 4s\n",
            "21:\tlearn: 0.2643172\ttotal: 48.8s\tremaining: 1m 2s\n",
            "22:\tlearn: 0.2602245\ttotal: 51s\tremaining: 59.9s\n",
            "23:\tlearn: 0.2563396\ttotal: 53.2s\tremaining: 57.6s\n",
            "24:\tlearn: 0.2529837\ttotal: 55.5s\tremaining: 55.5s\n",
            "25:\tlearn: 0.2492806\ttotal: 57.7s\tremaining: 53.2s\n",
            "26:\tlearn: 0.2465885\ttotal: 59.8s\tremaining: 51s\n",
            "27:\tlearn: 0.2434968\ttotal: 1m 1s\tremaining: 48.7s\n",
            "28:\tlearn: 0.2409987\ttotal: 1m 4s\tremaining: 46.5s\n",
            "29:\tlearn: 0.2387576\ttotal: 1m 6s\tremaining: 44.2s\n",
            "30:\tlearn: 0.2362795\ttotal: 1m 8s\tremaining: 42.1s\n",
            "31:\tlearn: 0.2343926\ttotal: 1m 10s\tremaining: 39.8s\n",
            "32:\tlearn: 0.2326599\ttotal: 1m 12s\tremaining: 37.6s\n",
            "33:\tlearn: 0.2309934\ttotal: 1m 15s\tremaining: 35.3s\n",
            "34:\tlearn: 0.2293845\ttotal: 1m 17s\tremaining: 33.1s\n",
            "35:\tlearn: 0.2279778\ttotal: 1m 19s\tremaining: 30.9s\n",
            "36:\tlearn: 0.2261872\ttotal: 1m 21s\tremaining: 28.7s\n",
            "37:\tlearn: 0.2249260\ttotal: 1m 23s\tremaining: 26.4s\n",
            "38:\tlearn: 0.2236593\ttotal: 1m 25s\tremaining: 24.2s\n",
            "39:\tlearn: 0.2226174\ttotal: 1m 28s\tremaining: 22s\n",
            "40:\tlearn: 0.2214552\ttotal: 1m 30s\tremaining: 19.8s\n",
            "41:\tlearn: 0.2204852\ttotal: 1m 32s\tremaining: 17.6s\n",
            "42:\tlearn: 0.2192882\ttotal: 1m 34s\tremaining: 15.4s\n",
            "43:\tlearn: 0.2183406\ttotal: 1m 36s\tremaining: 13.2s\n",
            "44:\tlearn: 0.2174500\ttotal: 1m 38s\tremaining: 11s\n",
            "45:\tlearn: 0.2165315\ttotal: 1m 40s\tremaining: 8.77s\n",
            "46:\tlearn: 0.2155231\ttotal: 1m 42s\tremaining: 6.57s\n",
            "47:\tlearn: 0.2146769\ttotal: 1m 45s\tremaining: 4.39s\n",
            "48:\tlearn: 0.2137508\ttotal: 1m 47s\tremaining: 2.19s\n",
            "49:\tlearn: 0.2129543\ttotal: 1m 49s\tremaining: 0us\n",
            "Лучший результат F1: 0.5442891512855376\n",
            "Лучшие гиперпараметры: {'model__depth': 6, 'model__iterations': 50, 'model__learning_rate': 0.05}\n"
          ]
        }
      ],
      "source": [
        "model_cb = training(catboost.CatBoostClassifier(),\n",
        "                    {\"model__learning_rate\": [0.01, 0.05], \"model__depth\": [4, 6], \"model__iterations\": [10, 50]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdwB3mk38G0k"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-81q8_PpI6MP",
        "outputId": "c764d9aa-0f44-4199-f714-cd864cb93db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "Лучший результат F1: 0.6960257669767893\n",
            "Лучшие гиперпараметры: {'model__learning_rate': 0.1, 'model__max_depth': 10}\n"
          ]
        }
      ],
      "source": [
        "model_lgbm = training(lightgbm.LGBMClassifier(),\n",
        "                    {\"model__learning_rate\": [0.01, 0.05, 0.1], \"model__max_depth\": [4, 6, 10]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHe_V7qUC5NP"
      },
      "source": [
        "**Вывод**: мы обучили три модели: логистическую регрессию, CatBoost и LightGBM.\n",
        "\n",
        "- у логистической регрессии с гиперпараметрами 'solver'='saga', 'C'=6, 'penalty'='l1'  F1 равен 0.7733771909698653\n",
        "- у CatBoost с гиперпараметрами 'depth'=6, 'iterations'=50, 'learning_rate'=0.05 F1 равен 0.5442891512855376\n",
        "- у LightGBM с гиперпараметрами 'learning_rate'=0.1, 'max_depth'=10 F1 равен 0.6960257669767893.\n",
        "\n",
        "Так как по условию исследования F1 должен быть не меньше 0.75, нам подходит только модель логистической регрессии. Проверим её на тестовой выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6gYH6aELeg"
      },
      "source": [
        "### Проверка на тестовой выборке и сравнение с константной моделью"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ifkF8HEKo3",
        "outputId": "62fb2c45-5f3b-42e3-abd9-5566acc66c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 логистической регрессии на тестовой выборке: 0.7865289145310613\n"
          ]
        }
      ],
      "source": [
        "predictions_lr_test = model_lr.predict(features_test)\n",
        "print(\"F1 логистической регрессии на тестовой выборке:\", f1_score(target_test, predictions_lr_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoMH3o9kFXas"
      },
      "source": [
        "F1 логистической регрессии на тестовой выборке составляет 0.7865289145310613, что превышает пороговое значение. Теперь проверим нашу модель на адекватность, сравнив её с константной моделью, которая всегда предсказывает \"1\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntaj0w0dI6MQ"
      },
      "outputs": [],
      "source": [
        "#векторизуем выборки для дамми-модели\n",
        "count_tf_idf = TfidfVectorizer(stop_words=stop_list, decode_error='ignore')\n",
        "\n",
        "features_train_vec = count_tf_idf.fit_transform(features_train)\n",
        "features_test_vec = count_tf_idf.transform(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TfajEvAFrRc",
        "outputId": "f2387cfd-f5ce-4915-f521-bb53ff6ac026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 константной модели на тестовой выборке: 0.1843754986664235\n"
          ]
        }
      ],
      "source": [
        "dummy_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dummy_clf.fit(features_train_vec, target_train)\n",
        "dummy_predictions = dummy_clf.predict(features_test_vec)\n",
        "print(\"F1 константной модели на тестовой выборке:\", f1_score(target_test, dummy_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTCjlZZVH7zd"
      },
      "source": [
        "Наша модель прошла проверку на адекватность: дамми-модель дала значение F1, равное 0.1843754986664235.\n",
        "\n",
        "**Таким образом, следует выбрать модель логистической регрессии с  гиперпараметрами 'solver'='saga', 'C'=6, 'penalty'='l1'.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSnxUZXu8G0l"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vFZpKnrIqMS"
      },
      "source": [
        "Мы провели исследование для интернет-магазина «Викишоп». Задачей исследования являлось построение модели, которая классифицирует комментарии пользователей на позитивные и негативные. Значением метрики качества модели F1 должно составлять не меньше 0.75.\n",
        "\n",
        "В ходе исследования мы:\n",
        "\n",
        "1) Считали исходный датасет и изучили его, а также подготовили данные для дальнейшего обучения: лемматизировали, очистили тексты от лишних символов, разделили датафрейм на обучающую и тестовую выборки.\n",
        "\n",
        "2) Обучили три модели: логистическую регрессию, CatBoost и LightGBM.\n",
        "\n",
        "- у логистической регрессии с гиперпараметрами 'solver'='saga', 'C'=6, 'penalty'='l1' F1 равен 0.7733771909698653\n",
        "- у CatBoost с гиперпараметрами 'depth'=6, 'iterations'=50, 'learning_rate'=0.05 F1 равен 0.5442891512855376\n",
        "- у LightGBM с гиперпараметрами 'learning_rate'=0.1, 'max_depth'=10 F1 равен 0.6960257669767893.\n",
        "\n",
        "Так как по условию исследования F1 должен быть не меньше 0.75, нам подходит только модель логистической регрессии. Мы выбрали  её для проверки на тестовой выборке.\n",
        "\n",
        "3) Проверили модель логистической регрессии на тестовой выборке.  F1 составило 0.7865289145310613, что превышает пороговое значение. Далее мы проверили модель на адекватность, сравнив её с константной моделью, которая всегда предсказывает \"1\". Наша модель прошла проверку на адекватность, так как дамми-модель дала значение F1, равное 0.1843754986664235.\n",
        "\n",
        "**Таким образом, следует выбрать модель логистической регрессии с гиперпараметрами 'solver'='saga', 'C'=6, 'penalty'='l1'.**"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 1934,
        "start_time": "2023-10-09T12:31:19.853Z"
      },
      {
        "duration": 1713,
        "start_time": "2023-10-09T12:32:15.997Z"
      },
      {
        "duration": 2257,
        "start_time": "2023-10-09T12:32:54.149Z"
      },
      {
        "duration": 15,
        "start_time": "2023-10-09T12:33:05.975Z"
      },
      {
        "duration": 32,
        "start_time": "2023-10-09T12:33:23.306Z"
      },
      {
        "duration": 217,
        "start_time": "2023-10-09T14:33:01.609Z"
      },
      {
        "duration": 172,
        "start_time": "2023-10-09T14:36:07.736Z"
      },
      {
        "duration": 16,
        "start_time": "2023-10-09T14:37:50.483Z"
      },
      {
        "duration": 43,
        "start_time": "2023-10-09T14:38:29.084Z"
      },
      {
        "duration": 44,
        "start_time": "2023-10-09T14:40:02.718Z"
      },
      {
        "duration": 43,
        "start_time": "2023-10-09T14:40:09.345Z"
      },
      {
        "duration": 1995,
        "start_time": "2023-10-09T14:41:00.186Z"
      },
      {
        "duration": 82,
        "start_time": "2023-10-09T14:43:34.522Z"
      },
      {
        "duration": 1835,
        "start_time": "2023-10-09T14:43:42.796Z"
      },
      {
        "duration": 2666,
        "start_time": "2023-10-09T14:43:44.634Z"
      },
      {
        "duration": 13,
        "start_time": "2023-10-09T14:43:47.303Z"
      },
      {
        "duration": 46,
        "start_time": "2023-10-09T14:43:47.318Z"
      },
      {
        "duration": 243,
        "start_time": "2023-10-09T14:43:47.367Z"
      },
      {
        "duration": 2173,
        "start_time": "2023-10-09T14:43:47.612Z"
      },
      {
        "duration": 4,
        "start_time": "2023-10-09T14:46:10.441Z"
      },
      {
        "duration": 16,
        "start_time": "2023-10-09T14:47:44.439Z"
      },
      {
        "duration": 1809,
        "start_time": "2023-10-09T14:48:14.250Z"
      },
      {
        "duration": 2589,
        "start_time": "2023-10-09T14:48:16.062Z"
      },
      {
        "duration": 12,
        "start_time": "2023-10-09T14:48:18.653Z"
      },
      {
        "duration": 86,
        "start_time": "2023-10-09T14:48:18.667Z"
      },
      {
        "duration": 259,
        "start_time": "2023-10-09T14:48:18.755Z"
      },
      {
        "duration": 2221,
        "start_time": "2023-10-09T14:48:19.015Z"
      },
      {
        "duration": 1896,
        "start_time": "2023-10-09T14:50:27.173Z"
      },
      {
        "duration": 2636,
        "start_time": "2023-10-09T14:50:29.071Z"
      },
      {
        "duration": 12,
        "start_time": "2023-10-09T14:50:31.709Z"
      },
      {
        "duration": 86,
        "start_time": "2023-10-09T14:50:31.723Z"
      },
      {
        "duration": 256,
        "start_time": "2023-10-09T14:50:31.811Z"
      },
      {
        "duration": 152050,
        "start_time": "2023-10-09T14:50:32.069Z"
      },
      {
        "duration": 1908,
        "start_time": "2023-10-09T14:57:41.718Z"
      },
      {
        "duration": 2720,
        "start_time": "2023-10-09T14:57:43.629Z"
      },
      {
        "duration": 12,
        "start_time": "2023-10-09T14:57:46.350Z"
      },
      {
        "duration": 37,
        "start_time": "2023-10-09T14:57:46.363Z"
      },
      {
        "duration": 290,
        "start_time": "2023-10-09T14:57:46.402Z"
      },
      {
        "duration": 154800,
        "start_time": "2023-10-09T14:57:46.694Z"
      },
      {
        "duration": 4621,
        "start_time": "2023-10-09T15:17:02.240Z"
      },
      {
        "duration": 4771,
        "start_time": "2023-10-09T15:17:19.620Z"
      },
      {
        "duration": 58,
        "start_time": "2023-10-09T15:22:30.479Z"
      },
      {
        "duration": 5,
        "start_time": "2023-10-09T15:24:12.367Z"
      },
      {
        "duration": 377,
        "start_time": "2023-10-09T15:26:33.624Z"
      },
      {
        "duration": 223,
        "start_time": "2023-10-09T17:07:27.523Z"
      },
      {
        "duration": 26,
        "start_time": "2023-10-09T17:09:05.377Z"
      },
      {
        "duration": 11831,
        "start_time": "2023-10-09T17:09:49.161Z"
      },
      {
        "duration": 6,
        "start_time": "2023-10-09T17:20:12.765Z"
      },
      {
        "duration": 7,
        "start_time": "2023-10-09T17:22:13.404Z"
      },
      {
        "duration": 7,
        "start_time": "2023-10-09T17:27:41.154Z"
      },
      {
        "duration": 19,
        "start_time": "2023-10-09T17:27:50.986Z"
      },
      {
        "duration": 370,
        "start_time": "2023-10-09T17:29:36.809Z"
      },
      {
        "duration": 19,
        "start_time": "2023-10-09T17:38:53.452Z"
      },
      {
        "duration": 1665,
        "start_time": "2023-10-09T17:39:35.149Z"
      },
      {
        "duration": 2059,
        "start_time": "2023-10-09T17:43:00.476Z"
      },
      {
        "duration": 1109,
        "start_time": "2023-10-09T17:43:02.542Z"
      },
      {
        "duration": 23,
        "start_time": "2023-10-09T17:43:03.657Z"
      },
      {
        "duration": 39,
        "start_time": "2023-10-09T17:43:03.684Z"
      },
      {
        "duration": 292,
        "start_time": "2023-10-09T17:43:03.727Z"
      },
      {
        "duration": 178609,
        "start_time": "2023-10-09T17:43:04.023Z"
      },
      {
        "duration": 6865,
        "start_time": "2023-10-09T17:46:02.634Z"
      },
      {
        "duration": 109,
        "start_time": "2023-10-09T17:46:09.502Z"
      },
      {
        "duration": 9788,
        "start_time": "2023-10-09T17:46:09.613Z"
      },
      {
        "duration": 430516,
        "start_time": "2023-10-09T17:46:19.403Z"
      },
      {
        "duration": 160222,
        "start_time": "2023-10-09T17:54:26.406Z"
      },
      {
        "duration": 1112351,
        "start_time": "2023-10-09T17:57:38.879Z"
      },
      {
        "duration": 1129631,
        "start_time": "2023-10-09T18:29:13.406Z"
      },
      {
        "duration": 2448,
        "start_time": "2023-10-09T18:54:29.214Z"
      },
      {
        "duration": 3787,
        "start_time": "2023-10-09T18:54:31.669Z"
      },
      {
        "duration": 25,
        "start_time": "2023-10-09T18:54:35.461Z"
      },
      {
        "duration": 91,
        "start_time": "2023-10-09T18:54:35.487Z"
      },
      {
        "duration": 310,
        "start_time": "2023-10-09T18:54:35.582Z"
      },
      {
        "duration": 202855,
        "start_time": "2023-10-09T18:54:35.898Z"
      },
      {
        "duration": 6883,
        "start_time": "2023-10-09T18:57:58.755Z"
      },
      {
        "duration": 68,
        "start_time": "2023-10-09T18:58:05.648Z"
      },
      {
        "duration": 10893,
        "start_time": "2023-10-09T18:58:05.718Z"
      },
      {
        "duration": 1140032,
        "start_time": "2023-10-09T18:58:16.613Z"
      },
      {
        "duration": 2686,
        "start_time": "2023-10-11T14:50:14.609Z"
      },
      {
        "duration": 2885,
        "start_time": "2023-10-11T14:50:17.298Z"
      },
      {
        "duration": 4455,
        "start_time": "2023-10-11T14:50:20.186Z"
      },
      {
        "duration": 43,
        "start_time": "2023-10-11T14:50:24.644Z"
      },
      {
        "duration": 201,
        "start_time": "2023-10-11T14:50:24.689Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.892Z"
      },
      {
        "duration": 1,
        "start_time": "2023-10-11T14:50:24.894Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.896Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.898Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.899Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.901Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.902Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.904Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.906Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.907Z"
      },
      {
        "duration": 0,
        "start_time": "2023-10-11T14:50:24.909Z"
      },
      {
        "duration": 2461,
        "start_time": "2023-10-12T09:39:18.983Z"
      },
      {
        "duration": 1841,
        "start_time": "2023-10-12T09:39:40.401Z"
      },
      {
        "duration": 2418,
        "start_time": "2023-10-12T09:39:46.065Z"
      },
      {
        "duration": 12,
        "start_time": "2023-10-12T09:39:51.328Z"
      },
      {
        "duration": 32,
        "start_time": "2023-10-12T09:41:28.229Z"
      },
      {
        "duration": 196,
        "start_time": "2023-10-12T09:41:29.061Z"
      },
      {
        "duration": 24,
        "start_time": "2023-10-12T09:58:40.467Z"
      },
      {
        "duration": 4662,
        "start_time": "2023-10-12T10:07:27.381Z"
      },
      {
        "duration": 425,
        "start_time": "2023-10-12T10:14:28.378Z"
      },
      {
        "duration": 1623,
        "start_time": "2023-10-12T10:14:55.907Z"
      },
      {
        "duration": 482,
        "start_time": "2023-10-12T10:17:57.267Z"
      },
      {
        "duration": 1097050,
        "start_time": "2023-10-12T10:20:07.356Z"
      },
      {
        "duration": 17,
        "start_time": "2023-10-12T10:41:12.625Z"
      },
      {
        "duration": 2342,
        "start_time": "2023-10-12T10:42:23.622Z"
      },
      {
        "duration": 30,
        "start_time": "2023-10-12T10:42:50.930Z"
      },
      {
        "duration": 6785,
        "start_time": "2023-10-12T10:42:55.673Z"
      },
      {
        "duration": 388,
        "start_time": "2023-10-12T10:45:15.034Z"
      },
      {
        "duration": 31,
        "start_time": "2023-10-12T10:45:22.201Z"
      },
      {
        "duration": 72145,
        "start_time": "2023-10-12T10:45:43.673Z"
      },
      {
        "duration": 1204874,
        "start_time": "2023-10-12T10:47:17.178Z"
      },
      {
        "duration": 4321,
        "start_time": "2023-10-12T11:11:28.354Z"
      },
      {
        "duration": 844,
        "start_time": "2023-10-12T11:11:32.677Z"
      },
      {
        "duration": 12,
        "start_time": "2023-10-12T11:11:33.523Z"
      },
      {
        "duration": 43,
        "start_time": "2023-10-12T11:11:33.536Z"
      },
      {
        "duration": 166,
        "start_time": "2023-10-12T11:11:33.581Z"
      },
      {
        "duration": 749,
        "start_time": "2023-10-12T11:11:33.749Z"
      },
      {
        "duration": 1109746,
        "start_time": "2023-10-12T11:11:34.500Z"
      },
      {
        "duration": 2355,
        "start_time": "2023-10-12T11:30:04.248Z"
      },
      {
        "duration": 29,
        "start_time": "2023-10-12T11:35:07.864Z"
      },
      {
        "duration": 5,
        "start_time": "2023-10-12T12:11:59.828Z"
      },
      {
        "duration": 206,
        "start_time": "2023-10-12T12:14:21.562Z"
      },
      {
        "duration": 7,
        "start_time": "2023-10-12T12:15:55.379Z"
      },
      {
        "duration": 1492,
        "start_time": "2023-10-12T12:16:02.611Z"
      },
      {
        "duration": 5,
        "start_time": "2023-10-12T12:16:39.275Z"
      },
      {
        "duration": 5,
        "start_time": "2023-10-12T12:16:59.788Z"
      },
      {
        "duration": 7170580,
        "start_time": "2023-10-13T00:56:24.212Z"
      },
      {
        "duration": 1824175,
        "start_time": "2023-10-13T10:49:35.797Z"
      },
      {
        "duration": 1745328,
        "start_time": "2023-10-13T11:19:59.974Z"
      },
      {
        "duration": 6669,
        "start_time": "2023-10-13T19:46:12.673Z"
      },
      {
        "duration": 21,
        "start_time": "2023-10-13T19:46:24.639Z"
      },
      {
        "duration": 27,
        "start_time": "2023-10-13T19:47:02.638Z"
      },
      {
        "duration": 28,
        "start_time": "2023-10-13T19:47:14.956Z"
      },
      {
        "duration": 1492,
        "start_time": "2023-10-13T19:48:44.841Z"
      },
      {
        "duration": 1695,
        "start_time": "2023-10-13T19:49:45.601Z"
      },
      {
        "duration": 26,
        "start_time": "2023-10-13T19:50:01.540Z"
      },
      {
        "duration": 6658,
        "start_time": "2023-10-13T19:50:42.713Z"
      },
      {
        "duration": 19,
        "start_time": "2023-10-13T19:51:21.492Z"
      }
    ],
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "241px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}